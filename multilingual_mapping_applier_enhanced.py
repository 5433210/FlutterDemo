#!/usr/bin/env python3
"""
å¤šè¯­è¨€æ˜ å°„æ–‡ä»¶åº”ç”¨å™¨ - æ”¯æŒå¹²è¿è¡Œæ¨¡å¼
åŸºäºæ˜ å°„æ–‡ä»¶åº”ç”¨ä»£ç æ›¿æ¢å’ŒARBæ›´æ–°
å¢å¼ºç‰ˆæœ¬ï¼šæ”¯æŒYAMLè¯­æ³•ä¿®å¤å’Œæ¨¡æ¿è¯­æ³•å¤„ç†
"""

import os
import re
import json
import yaml
import glob
import argparse
from collections import OrderedDict
from datetime import datetime

# é…ç½®å¸¸é‡
CODE_DIR = "lib"
ARB_DIR = "lib/l10n"
ZH_ARB_PATH = os.path.join(ARB_DIR, "app_zh.arb")
EN_ARB_PATH = os.path.join(ARB_DIR, "app_en.arb")

class MultilingualMappingApplier:
    def __init__(self, mapping_file_path, dry_run=False):
        self.mapping_file_path = mapping_file_path
        self.dry_run = dry_run
        self.mapping_data = None
        self.zh_arb_data = OrderedDict()
        self.en_arb_data = OrderedDict()
        self.changes_preview = []
        
    def load_mapping_file(self):
        """åŠ è½½æ˜ å°„æ–‡ä»¶"""
        try:
            with open(self.mapping_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # é¢„å¤„ç†å†…å®¹ï¼Œå¤„ç†æ¨¡æ¿è¯­æ³•å’Œç‰¹æ®Šå­—ç¬¦
            content = self.preprocess_yaml_content(content)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯OrderedDictæ ¼å¼
            if '!!python/object/apply:collections.OrderedDict' in content:
                # ä½¿ç”¨unsafe_loadå¤„ç†OrderedDictæ ¼å¼
                self.mapping_data = yaml.unsafe_load(content)
                print(f"âœ… æˆåŠŸåŠ è½½æ˜ å°„æ–‡ä»¶ (OrderedDictæ ¼å¼): {self.mapping_file_path}")
            else:
                # æ ‡å‡†YAMLæ ¼å¼
                self.mapping_data = yaml.safe_load(content)
                print(f"âœ… æˆåŠŸåŠ è½½æ˜ å°„æ–‡ä»¶ (æ ‡å‡†YAMLæ ¼å¼): {self.mapping_file_path}")
            
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
            print(f"æ–‡ä»¶è·¯å¾„: {self.mapping_file_path}")
            return False
    
    def preprocess_yaml_content(self, content):
        """é¢„å¤„ç†YAMLå†…å®¹ï¼Œä¿®å¤å¸¸è§çš„è¯­æ³•é—®é¢˜"""
        # æ‰¾åˆ°æ‰€æœ‰åŒ…å« {xxx} çš„è¡Œå¹¶ä¿®å¤
        lines = content.split('\n')
        fixed_lines = []
        fixed_count = 0
        
        for line in lines:
            original_line = line
            # æ£€æŸ¥æ˜¯å¦åŒ…å« {xxx} æ¨¡å¼ä¸”ä¸åœ¨å¼•å·å†…
            if re.search(r'\{[^}]+\}', line) and ':' in line:
                # å¦‚æœè¡ŒåŒ…å«å†’å·å’Œå¤§æ‹¬å·ï¼Œç¡®ä¿å€¼éƒ¨åˆ†è¢«æ­£ç¡®å¼•ç”¨
                if ': ' in line:
                    key_part, value_part = line.split(': ', 1)
                    # å¦‚æœå€¼éƒ¨åˆ†åŒ…å« {xxx} ä¸”æ²¡æœ‰è¢«å¼•å·åŒ…å›´ï¼Œæ·»åŠ å¼•å·
                    if re.search(r'\{[^}]+\}', value_part):
                        if not (value_part.startswith('"') and value_part.endswith('"')):
                            if not (value_part.startswith("'") and value_part.endswith("'")):
                                line = f"{key_part}: \"{value_part}\""
                                fixed_count += 1
            
            fixed_lines.append(line)
        
        if fixed_count > 0:
            print(f"ğŸ”§ ä¿®å¤äº† {fixed_count} ä¸ªYAMLè¯­æ³•é—®é¢˜")
        
        return '\n'.join(fixed_lines)
    
    def load_arb_files(self):
        """åŠ è½½ç°æœ‰ARBæ–‡ä»¶"""
        # åŠ è½½ä¸­æ–‡ARB
        if os.path.exists(ZH_ARB_PATH):
            with open(ZH_ARB_PATH, 'r', encoding='utf-8') as f:
                self.zh_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        # åŠ è½½è‹±æ–‡ARB
        if os.path.exists(EN_ARB_PATH):
            with open(EN_ARB_PATH, 'r', encoding='utf-8') as f:
                self.en_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        print(f"âœ… å·²åŠ è½½ARBæ–‡ä»¶ - ä¸­æ–‡: {len(self.zh_arb_data)} é”®, è‹±æ–‡: {len(self.en_arb_data)} é”®")
    
    def analyze_mappings(self):
        """åˆ†ææ˜ å°„æ•°æ®ï¼Œç»Ÿè®¡å„ç§æ“ä½œ"""
        stats = {
            'total_items': 0,
            'approved_items': 0,
            'reuse_items': 0,
            'create_items': 0,
            'chinese_items': 0,
            'english_items': 0
        }
        
        # Debug: æ‰“å°æ˜ å°„æ•°æ®ç»“æ„
        print(f"ğŸ” æ˜ å°„æ•°æ®ç±»å‹: {type(self.mapping_data)}")
        if isinstance(self.mapping_data, dict):
            print(f"ğŸ” æ˜ å°„æ•°æ®é”®: {list(self.mapping_data.keys())}")
            for key, value in list(self.mapping_data.items())[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                print(f"ğŸ” {key}: {type(value)} - {len(value) if isinstance(value, (list, dict)) else 'N/A'}")
          # å¤„ç†OrderedDictæ ¼å¼çš„æ•°æ®ç»“æ„
        if isinstance(self.mapping_data, OrderedDict):
            # OrderedDictæ ¼å¼: [(key, value), ...]
            for lang_key, lang_mappings in self.mapping_data.items():
                if isinstance(lang_mappings, OrderedDict):
                    for arb_key, mapping_data in lang_mappings.items():
                        stats['total_items'] += 1
                        if mapping_data.get('approved', False):
                            stats['approved_items'] += 1
                        if 'reuse' in mapping_data.get('action', ''):
                            stats['reuse_items'] += 1
                        elif 'create' in mapping_data.get('action', ''):
                            stats['create_items'] += 1
                        if 'chinese' in lang_key.lower():
                            stats['chinese_items'] += 1
                        elif 'english' in lang_key.lower():
                            stats['english_items'] += 1
        else:
            # æ ‡å‡†å­—å…¸æ ¼å¼
            for lang_key, lang_mappings in self.mapping_data.items():
                if isinstance(lang_mappings, list):
                    for item in lang_mappings:
                        stats['total_items'] += 1
                        if item.get('approved', False):
                            stats['approved_items'] += 1
                        if item.get('action') == 'reuse':
                            stats['reuse_items'] += 1
                        elif item.get('action') == 'create':
                            stats['create_items'] += 1
                        if lang_key == 'chinese':
                            stats['chinese_items'] += 1
                        elif lang_key == 'english':
                            stats['english_items'] += 1
          return stats
    
    def process_code_replacements(self):
        """å¤„ç†ä»£ç æ›¿æ¢"""
        code_changes = []
        
        # å¤„ç†æ˜ å°„æ•°æ®
        for lang_key, lang_mappings in self.mapping_data.items():
            if not isinstance(lang_mappings, (list, OrderedDict)):
                continue
            
            # å¤„ç†OrderedDictç»“æ„
            if isinstance(lang_mappings, OrderedDict):
                for arb_key, mapping_data in lang_mappings.items():
                    if not mapping_data.get('approved', False):
                        continue
                    
                    file_path = mapping_data.get('file')
                    original_text = mapping_data.get('text_zh') or mapping_data.get('text_en') or mapping_data.get('original')
                    
                    if not all([file_path, original_text, arb_key]):
                        continue
                    
                    # ç”Ÿæˆæ›¿æ¢æ–‡æœ¬
                    replacement = f"S.of(context).{arb_key}"
                    
                    code_changes.append({
                        'file': file_path,
                        'original': original_text,
                        'replacement': replacement,
                        'arb_key': arb_key,
                        'language': lang_key,
                        'line': mapping_data.get('line', 0)
                    })
            else:
                # å¤„ç†åˆ—è¡¨ç»“æ„ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                for item in lang_mappings:
                    mapping_data = item
                    
                    # å¤„ç†OrderedDictæ ¼å¼
                    if isinstance(item, list) and len(item) > 1:
                        mapping_data = item[1]
                    
                    if not mapping_data.get('approved', False):
                        continue
                    
                    file_path = mapping_data.get('file')
                    original_text = mapping_data.get('text_zh') or mapping_data.get('text_en') or mapping_data.get('original')
                    arb_key = item[0] if isinstance(item, list) else mapping_data.get('arb_key')
                    
                    if not all([file_path, original_text, arb_key]):
                        continue
                    
                    # ç”Ÿæˆæ›¿æ¢æ–‡æœ¬
                    replacement = f"S.of(context).{arb_key}"
                    
                    code_changes.append({
                        'file': file_path,
                        'original': original_text,
                        'replacement': replacement,
                        'arb_key': arb_key,
                        'language': lang_key,
                        'line': mapping_data.get('line', 0)
                    })
        
        return code_changes
      def process_arb_updates(self):
        """å¤„ç†ARBæ–‡ä»¶æ›´æ–°"""
        zh_updates = {}
        en_updates = {}
        
        for lang_key, lang_mappings in self.mapping_data.items():
            if not isinstance(lang_mappings, (list, OrderedDict)):
                continue
            
            # å¤„ç†OrderedDictç»“æ„
            if isinstance(lang_mappings, OrderedDict):
                for arb_key, mapping_data in lang_mappings.items():
                    if not mapping_data.get('approved', False):
                        continue
                    
                    action = mapping_data.get('action', '')
                    
                    if 'create' in action:
                        text_zh = mapping_data.get('text_zh')
                        text_en = mapping_data.get('text_en')
                        
                        if text_zh and arb_key not in self.zh_arb_data:
                            zh_updates[arb_key] = text_zh
                        
                        if text_en and arb_key not in self.en_arb_data:
                            en_updates[arb_key] = text_en
            else:
                # å¤„ç†åˆ—è¡¨ç»“æ„ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                for item in lang_mappings:
                    mapping_data = item
                    
                    # å¤„ç†OrderedDictæ ¼å¼
                    if isinstance(item, list) and len(item) > 1:
                        arb_key = item[0]
                        mapping_data = item[1]
                    else:
                        arb_key = mapping_data.get('arb_key')
                    
                    if not mapping_data.get('approved', False):
                        continue
                    
                    action = mapping_data.get('action', '')
                    
                    if 'create' in action and arb_key:
                        text_zh = mapping_data.get('text_zh')
                        text_en = mapping_data.get('text_en')
                        
                        if text_zh and arb_key not in self.zh_arb_data:
                            zh_updates[arb_key] = text_zh
                        
                        if text_en and arb_key not in self.en_arb_data:
                            en_updates[arb_key] = text_en
        
        return zh_updates, en_updates
    
    def preview_changes(self):
        """é¢„è§ˆæ‰€æœ‰æ›´æ”¹"""
        print("\nğŸ” === æ˜ å°„æ–‡ä»¶åº”ç”¨é¢„è§ˆ ===")
        
        # åˆ†ææ˜ å°„
        stats = self.analyze_mappings()
        print(f"\nğŸ“Š === æ˜ å°„ç»Ÿè®¡ ===")
        print(f"æ€»æ¡ç›®æ•°: {stats['total_items']}")
        print(f"å·²å®¡æ ¸æ¡ç›®: {stats['approved_items']}")
        print(f"å¤ç”¨æ¡ç›®: {stats['reuse_items']}")
        print(f"æ–°å»ºæ¡ç›®: {stats['create_items']}")
        print(f"ä¸­æ–‡æ¡ç›®: {stats['chinese_items']}")
        print(f"è‹±æ–‡æ¡ç›®: {stats['english_items']}")
        
        # ARBæ›´æ–°é¢„è§ˆ
        zh_updates, en_updates = self.process_arb_updates()
        print(f"\nğŸ“ === ARBæ–‡ä»¶æ›´æ”¹é¢„è§ˆ ===")
        
        total_new_keys = len(zh_updates) + len(en_updates)
        print(f"å°†æ·»åŠ  {total_new_keys} ä¸ªæ–°é”®åˆ°ARBæ–‡ä»¶:")
        
        # åˆå¹¶æ˜¾ç¤ºä¸­è‹±æ–‡é”®
        all_keys = set(zh_updates.keys()) | set(en_updates.keys())
        for key in sorted(all_keys):
            print(f"  {key}:")
            if key in zh_updates:
                print(f"    zh: {zh_updates[key]}")
            if key in en_updates:
                print(f"    en: {en_updates[key]}")
        
        # ä»£ç æ›¿æ¢é¢„è§ˆ
        code_changes = self.process_code_replacements()
        print(f"\nğŸ”§ === ä»£ç æ›´æ”¹é¢„è§ˆ ===")
        print(f"å°†æ›´æ”¹ {len(code_changes)} å¤„ä»£ç :")
        
        for i, change in enumerate(code_changes):
            print(f"  æ–‡ä»¶: {change['file']}")
            print(f"  è¡Œå·: {change['line']}")
            print(f"  åŸæ–‡: \"{change['original']}\"")
            print(f"  æ›¿æ¢: {change['replacement']}")
            if i < len(code_changes) - 1:
                print()
        
        return len(code_changes) > 0 or total_new_keys > 0
    
    def apply_code_changes(self, code_changes):
        """åº”ç”¨ä»£ç æ›´æ”¹"""
        files_changed = set()
        
        for change in code_changes:
            file_path = change['file']
            original = change['original']
            replacement = change['replacement']
            
            # è½¬æ¢è·¯å¾„æ ¼å¼
            if '\\' in file_path and not file_path.startswith('lib'):
                file_path = file_path.replace('\\', '/')
            if not file_path.startswith('lib/'):
                file_path = 'lib/' + file_path.lstrip('/')
            
            if not os.path.exists(file_path):
                print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue
            
            try:
                # è¯»å–æ–‡ä»¶
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç¡®ä¿åŸæ–‡å­˜åœ¨äºæ–‡ä»¶ä¸­
                if original not in content:
                    print(f"âš ï¸  åœ¨ {file_path} ä¸­æ‰¾ä¸åˆ°åŸæ–‡: {original[:30]}...")
                    continue
                
                # æ›¿æ¢æ–‡æœ¬
                new_content = content.replace(original, replacement)
                
                if not self.dry_run:
                    # å¤‡ä»½åŸæ–‡ä»¶
                    backup_path = f"{file_path}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    # å†™å…¥æ–°å†…å®¹
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                
                files_changed.add(file_path)
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        
        return files_changed
    
    def apply_arb_changes(self, zh_updates, en_updates):
        """åº”ç”¨ARBæ–‡ä»¶æ›´æ”¹"""
        arb_files_changed = []
        
        # æ›´æ–°ä¸­æ–‡ARB
        if zh_updates:
            for key, value in zh_updates.items():
                self.zh_arb_data[key] = value
            
            if not self.dry_run:
                # å¤‡ä»½
                backup_path = f"{ZH_ARB_PATH}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                if os.path.exists(ZH_ARB_PATH):
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(dict(self.zh_arb_data), f, ensure_ascii=False, indent=2)
                
                # å†™å…¥æ›´æ–°
                with open(ZH_ARB_PATH, 'w', encoding='utf-8') as f:
                    json.dump(dict(self.zh_arb_data), f, ensure_ascii=False, indent=2)
            
            arb_files_changed.append(ZH_ARB_PATH)
        
        # æ›´æ–°è‹±æ–‡ARB
        if en_updates:
            for key, value in en_updates.items():
                self.en_arb_data[key] = value
            
            if not self.dry_run:
                # å¤‡ä»½
                backup_path = f"{EN_ARB_PATH}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                if os.path.exists(EN_ARB_PATH):
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(dict(self.en_arb_data), f, ensure_ascii=False, indent=2)
                
                # å†™å…¥æ›´æ–°
                with open(EN_ARB_PATH, 'w', encoding='utf-8') as f:
                    json.dump(dict(self.en_arb_data), f, ensure_ascii=False, indent=2)
            
            arb_files_changed.append(EN_ARB_PATH)
        
        return arb_files_changed
    
    def run_preview(self):
        """è¿è¡Œé¢„è§ˆæ¨¡å¼"""
        if not self.load_mapping_file():
            return False
        
        self.load_arb_files()
        return self.preview_changes()
    
    def apply_changes(self):
        """åº”ç”¨æ‰€æœ‰æ›´æ”¹"""
        print("\n=== ğŸš€ æ­£å¼åº”ç”¨æ›´æ”¹ ===")
        
        if not self.load_mapping_file():
            return False
        
        self.load_arb_files()
        
        # å¤„ç†ä»£ç æ›¿æ¢
        code_changes = self.process_code_replacements()
        files_changed = self.apply_code_changes(code_changes)
        
        # å¤„ç†ARBæ›´æ–°
        zh_updates, en_updates = self.process_arb_updates()
        arb_files_changed = self.apply_arb_changes(zh_updates, en_updates)
        
        # æŠ¥å‘Šç»“æœ
        print(f"\nâœ… åº”ç”¨å®Œæˆ!")
        if files_changed:
            print(f"ğŸ“ å·²ä¿®æ”¹ {len(files_changed)} ä¸ªä»£ç æ–‡ä»¶")
        if arb_files_changed:
            print(f"ğŸŒ å·²æ›´æ–° {len(arb_files_changed)} ä¸ªARBæ–‡ä»¶")
        
        return True

def find_latest_mapping_file():
    """æŸ¥æ‰¾æœ€æ–°çš„æ˜ å°„æ–‡ä»¶"""
    pattern = "**/multilingual_mapping_*.yaml"
    files = glob.glob(pattern, recursive=True)
    
    if not files:
        print("âŒ æœªæ‰¾åˆ°æ˜ å°„æ–‡ä»¶")
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def main():
    parser = argparse.ArgumentParser(description='å¤šè¯­è¨€æ˜ å°„æ–‡ä»¶åº”ç”¨å™¨')
    parser.add_argument('--input', '-i', help='æ˜ å°„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dry-run', '-d', action='store_true', help='å¹²è¿è¡Œæ¨¡å¼ï¼Œåªé¢„è§ˆæ›´æ”¹')
    parser.add_argument('--auto-latest', '-a', action='store_true', help='è‡ªåŠ¨ä½¿ç”¨æœ€æ–°æ˜ å°„æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜ å°„æ–‡ä»¶
    mapping_file = None
    
    if args.auto_latest:
        mapping_file = find_latest_mapping_file()
        if mapping_file:
            print(f"ä½¿ç”¨æœ€æ–°æ˜ å°„æ–‡ä»¶: {mapping_file}")
    elif args.input:
        mapping_file = args.input
    else:
        print("âŒ è¯·æŒ‡å®šæ˜ å°„æ–‡ä»¶è·¯å¾„æˆ–ä½¿ç”¨ --auto-latest é€‰é¡¹")
        return
    
    if not mapping_file or not os.path.exists(mapping_file):
        print(f"âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
        return
    
    # åˆ›å»ºåº”ç”¨å™¨
    applier = MultilingualMappingApplier(mapping_file, dry_run=args.dry_run)
    
    if args.dry_run:
        # é¢„è§ˆæ¨¡å¼
        success = applier.run_preview()
        if success:
            print("\nâœ… é¢„è§ˆå®Œæˆï¼å¦‚æœç¡®è®¤æ— è¯¯ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°æ­£å¼åº”ç”¨æ›´æ”¹ã€‚")
    else:
        # å®é™…åº”ç”¨
        print("âš ï¸  å³å°†åº”ç”¨æ›´æ”¹ï¼Œè¿™å°†ä¿®æ”¹ä»£ç æ–‡ä»¶å’ŒARBæ–‡ä»¶ã€‚")
        confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): ")
        if confirm.lower() == 'y':
            applier.apply_changes()
            print("\nğŸ‰ åº”ç”¨å®Œæˆï¼")
        else:
            print("å·²å–æ¶ˆæ“ä½œã€‚")

if __name__ == "__main__":
    main()
