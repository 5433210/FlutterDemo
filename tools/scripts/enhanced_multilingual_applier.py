#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå¤šè¯­è¨€æ˜ å°„åº”ç”¨å™¨ - æ­£ç¡®å¤„ç†Flutteræœ¬åœ°åŒ–
åŒ…å«å¯¼å…¥æ·»åŠ ã€ä¸Šä¸‹æ–‡å¤„ç†ã€æ–‡ä»¶ç»“æ„åˆ†æç­‰å®Œæ•´åŠŸèƒ½
"""

import os
import re
import json
import yaml
import glob
import argparse
from collections import OrderedDict
from datetime import datetime

# é…ç½®å¸¸é‡
CODE_DIR = "lib"
ARB_DIR = "lib/l10n"
ZH_ARB_PATH = os.path.join(ARB_DIR, "app_zh.arb")
EN_ARB_PATH = os.path.join(ARB_DIR, "app_en.arb")

class EnhancedMappingApplier:
    def __init__(self, mapping_file_path, dry_run=False):
        self.mapping_file_path = mapping_file_path
        self.dry_run = dry_run
        self.mapping_data = None
        self.zh_arb_data = OrderedDict()
        self.en_arb_data = OrderedDict()
        self.changes_preview = []
        
    def load_mapping_file(self):
        """åŠ è½½æ˜ å°„æ–‡ä»¶"""
        try:
            with open(self.mapping_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # é¢„å¤„ç†å†…å®¹ï¼Œä¿®å¤YAMLè¯­æ³•é—®é¢˜
            content = self.preprocess_yaml_content(content)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯OrderedDictæ ¼å¼
            if '!!python/object/apply:collections.OrderedDict' in content:
                self.mapping_data = yaml.unsafe_load(content)
                print(f"âœ… æˆåŠŸåŠ è½½æ˜ å°„æ–‡ä»¶ (OrderedDictæ ¼å¼): {self.mapping_file_path}")
            else:
                self.mapping_data = yaml.safe_load(content)
                print(f"âœ… æˆåŠŸåŠ è½½æ˜ å°„æ–‡ä»¶ (æ ‡å‡†YAMLæ ¼å¼): {self.mapping_file_path}")
            
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def preprocess_yaml_content(self, content):
        """é¢„å¤„ç†YAMLå†…å®¹ï¼Œä¿®å¤å¸¸è§è¯­æ³•é—®é¢˜"""
        lines = content.split('\n')
        fixed_lines = []
        fixed_count = 0
        
        for line in lines:
            # ä¿®å¤ {xxx} æ¨¡æ¿è¯­æ³•
            if re.search(r'\{[^}]+\}', line) and ':' in line:
                if ': ' in line:
                    key_part, value_part = line.split(': ', 1)
                    if re.search(r'\{[^}]+\}', value_part):
                        if not (value_part.startswith('"') and value_part.endswith('"')):
                            if not (value_part.startswith("'") and value_part.endswith("'")):
                                line = f"{key_part}: \"{value_part}\""
                                fixed_count += 1
            fixed_lines.append(line)
        
        if fixed_count > 0:
            print(f"ğŸ”§ ä¿®å¤äº† {fixed_count} ä¸ªYAMLè¯­æ³•é—®é¢˜")
        
        return '\n'.join(fixed_lines)
    
    def load_arb_files(self):
        """åŠ è½½ARBæ–‡ä»¶"""
        if os.path.exists(ZH_ARB_PATH):
            with open(ZH_ARB_PATH, 'r', encoding='utf-8') as f:
                self.zh_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        if os.path.exists(EN_ARB_PATH):
            with open(EN_ARB_PATH, 'r', encoding='utf-8') as f:
                self.en_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        print(f"âœ… å·²åŠ è½½ARBæ–‡ä»¶ - ä¸­æ–‡: {len(self.zh_arb_data)} é”®, è‹±æ–‡: {len(self.en_arb_data)} é”®")
    
    def analyze_dart_file(self, file_path):
        """åˆ†æDartæ–‡ä»¶ç»“æ„ï¼Œç¡®å®šæœ¬åœ°åŒ–é›†æˆæ–¹å¼"""
        if not os.path.exists(file_path):
            return None
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        analysis = {
            'has_material_import': 'package:flutter/material.dart' in content,
            'has_l10n_import': any(
                'flutter_gen/gen_l10n' in line or 
                'app_localizations' in line.lower() or
                'generated/l10n' in line
                for line in content.split('\n')
            ),
            'has_build_context': 'BuildContext' in content,
            'is_widget_class': 'extends StatelessWidget' in content or 'extends StatefulWidget' in content,
            'is_state_class': 'extends State<' in content,
            'widget_class_name': None,
            'existing_imports': [],
            'needs_context_access': False
        }
        
        # æå–å¯¼å…¥è¯­å¥
        import_lines = []
        for line in content.split('\n'):
            if line.strip().startswith('import '):
                import_lines.append(line.strip())
        analysis['existing_imports'] = import_lines
        
        # æŸ¥æ‰¾Widgetç±»å
        widget_match = re.search(r'class\s+(\w+)\s+extends\s+(StatelessWidget|StatefulWidget)', content)
        if widget_match:
            analysis['widget_class_name'] = widget_match.group(1)
          # æ£€æŸ¥æ˜¯å¦éœ€è¦contextè®¿é—®ï¼ˆåœ¨buildæ–¹æ³•å†…æˆ–æœ‰contextå‚æ•°çš„æ–¹æ³•å†…ï¼‰
        build_method_match = re.search(r'Widget\s+build\s*\([^)]*BuildContext[^)]*context[^)]*\)', content)
        analysis['needs_context_access'] = bool(build_method_match)
        
        return analysis
    
    def generate_l10n_import(self):
        """ç”Ÿæˆæœ¬åœ°åŒ–å¯¼å…¥è¯­å¥"""
        return "import 'package:flutter_gen/gen_l10n/app_localizations.dart';"
    
    def process_code_replacements(self):
        """å¤„ç†ä»£ç æ›¿æ¢ï¼ŒåŒ…å«å®Œæ•´çš„æœ¬åœ°åŒ–é›†æˆ"""
        code_changes = []
        
        # å¤„ç†æ ‡å‡†æ ¼å¼çš„æ˜ å°„æ•°æ®
        for lang_key, lang_data in self.mapping_data.items():
            if not isinstance(lang_data, dict):
                continue
            
            # éå†è¯­è¨€æ•°æ®ä¸‹çš„åˆ†ç±»ï¼ˆå¦‚ ui_text_widgetï¼‰
            for category, mappings in lang_data.items():
                if not isinstance(mappings, dict):
                    continue
                
                # éå†å…·ä½“çš„æ˜ å°„é¡¹
                for arb_key, mapping_data in mappings.items():
                    if not isinstance(mapping_data, dict):
                        continue
                    
                    if not mapping_data.get('approved', False):
                        continue
                    
                    file_path = mapping_data.get('file')
                    text_zh = mapping_data.get('text_zh')
                    text_en = mapping_data.get('text_en')
                    
                    # æ ¹æ®è¯­è¨€é”®é€‰æ‹©åŸå§‹æ–‡æœ¬
                    if 'chinese' in lang_key.lower() and text_zh:
                        original_text = text_zh
                    elif 'english' in lang_key.lower() and text_en:
                        original_text = text_en
                    else:
                        original_text = text_zh or text_en
                    
                    if not all([file_path, original_text, arb_key]):
                        continue
                    
                    # åˆ†ææ–‡ä»¶å¹¶ç”Ÿæˆå®Œæ•´çš„æ›´æ”¹
                    change = self.create_comprehensive_change(file_path, original_text, arb_key, mapping_data)
                    if change:
                        code_changes.append(change)
        
        return code_changes
    
    def create_comprehensive_change(self, file_path, original_text, arb_key, mapping_data):
        """åˆ›å»ºåŒ…å«å¯¼å…¥å’Œä¸Šä¸‹æ–‡å¤„ç†çš„å®Œæ•´æ›´æ”¹"""
        # æ ‡å‡†åŒ–æ–‡ä»¶è·¯å¾„
        if '\\' in file_path:
            file_path = file_path.replace('\\', '/')
        if not file_path.startswith('lib/'):
            file_path = 'lib/' + file_path.lstrip('/')
        
        if not os.path.exists(file_path):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        # åˆ†ææ–‡ä»¶ç»“æ„
        analysis = self.analyze_dart_file(file_path)
        if not analysis:
            return None
        
        # ç¡®å®šæ›¿æ¢ç­–ç•¥
        replacement_strategy = self.determine_replacement_strategy(analysis, original_text)
        
        return {
            'file': file_path,
            'original': original_text,
            'arb_key': arb_key,
            'line': mapping_data.get('line', 0),
            'analysis': analysis,
            'strategy': replacement_strategy,
            'import_needed': not analysis['has_l10n_import'],
            'context_access': replacement_strategy['context_method']
        }
    
    def determine_replacement_strategy(self, analysis, original_text):
        """ç¡®å®šæ›¿æ¢ç­–ç•¥"""
        strategy = {
            'context_method': 'AppLocalizations.of(context)!',
            'needs_import': not analysis['has_l10n_import'],
            'context_available': analysis['needs_context_access'],
            'widget_type': 'unknown'
        }
        
        if analysis['is_widget_class']:
            strategy['widget_type'] = 'widget'
            strategy['context_method'] = 'AppLocalizations.of(context)!'
        elif analysis['is_state_class']:
            strategy['widget_type'] = 'state'
            strategy['context_method'] = 'AppLocalizations.of(context)!'
        else:
            # å¯¹äºéWidgetç±»ï¼Œå¯èƒ½éœ€è¦ä¼ é€’context
            strategy['widget_type'] = 'other'
            strategy['context_method'] = 'AppLocalizations.of(context)!'
            strategy['needs_context_param'] = True
        
        return strategy
    
    def apply_code_changes(self, code_changes):
        """åº”ç”¨ä»£ç æ›´æ”¹ï¼ŒåŒ…å«å¯¼å…¥å’Œä¸Šä¸‹æ–‡å¤„ç†"""
        files_changed = set()
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„æ›´æ”¹
        changes_by_file = {}
        for change in code_changes:
            file_path = change['file']
            if file_path not in changes_by_file:
                changes_by_file[file_path] = []
            changes_by_file[file_path].append(change)
        
        # é€æ–‡ä»¶å¤„ç†
        for file_path, file_changes in changes_by_file.items():
            try:
                success = self.apply_changes_to_file(file_path, file_changes)
                if success:
                    files_changed.add(file_path)
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        
        return files_changed
    
    def apply_changes_to_file(self, file_path, changes):
        """å¯¹å•ä¸ªæ–‡ä»¶åº”ç”¨æ‰€æœ‰æ›´æ”¹"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ å¯¼å…¥
        needs_import = any(change['import_needed'] for change in changes)
        
        if needs_import:
            content = self.add_l10n_import(content)
        
        # åº”ç”¨æ–‡æœ¬æ›¿æ¢
        for change in changes:
            original_text = change['original']
            arb_key = change['arb_key']
            strategy = change['strategy']
            
            # æ„å»ºæ›¿æ¢æ–‡æœ¬
            replacement = f"{strategy['context_method']}.{arb_key}"
            
            # æ‰§è¡Œæ›¿æ¢
            if original_text in content:
                content = content.replace(f'"{original_text}"', replacement)
                content = content.replace(f"'{original_text}'", replacement)
                print(f"  âœ… æ›¿æ¢: {original_text} -> {replacement}")
            else:
                print(f"  âš ï¸  æœªæ‰¾åˆ°æ–‡æœ¬: {original_text}")
        
        # ä¿å­˜æ–‡ä»¶
        if content != original_content:
            if not self.dry_run:
                # å¤‡ä»½åŸæ–‡ä»¶
                backup_path = f"{file_path}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(original_content)
                
                # å†™å…¥æ–°å†…å®¹
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
            
            return True
        
        return False
    
    def add_l10n_import(self, content):
        """æ·»åŠ æœ¬åœ°åŒ–å¯¼å…¥åˆ°æ–‡ä»¶é¡¶éƒ¨"""
        lines = content.split('\n')
        
        # æŸ¥æ‰¾å¯¼å…¥è¯­å¥çš„æ’å…¥ä½ç½®
        import_insert_index = 0
        last_import_index = -1
        
        for i, line in enumerate(lines):
            if line.strip().startswith('import '):
                last_import_index = i
            elif line.strip().startswith('part '):
                # partè¯­å¥åº”è¯¥åœ¨importsä¹‹å
                break
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ¬åœ°åŒ–å¯¼å…¥
        l10n_import = self.generate_l10n_import()
        if any('app_localizations' in line.lower() or 'flutter_gen/gen_l10n' in line for line in lines):
            print("  ğŸ“¦ æœ¬åœ°åŒ–å¯¼å…¥å·²å­˜åœ¨")
            return content
          # æ’å…¥å¯¼å…¥è¯­å¥
        if last_import_index >= 0:
            insert_index = last_import_index + 1
        else:
            # å¦‚æœæ²¡æœ‰importè¯­å¥ï¼Œåœ¨æ–‡ä»¶å¼€å¤´æ’å…¥
            insert_index = 0
            
        lines.insert(insert_index, l10n_import)
        print(f"  ğŸ“¦ æ·»åŠ å¯¼å…¥: {l10n_import}")
        
        return '\n'.join(lines)
    
    def process_arb_updates(self):
        """å¤„ç†ARBæ–‡ä»¶æ›´æ–°"""
        zh_updates = {}
        en_updates = {}
        
        # å¤„ç†æ ‡å‡†æ ¼å¼çš„æ˜ å°„æ•°æ®
        for lang_key, lang_data in self.mapping_data.items():
            if not isinstance(lang_data, dict):
                continue
            
            # éå†è¯­è¨€æ•°æ®ä¸‹çš„åˆ†ç±»
            for category, mappings in lang_data.items():
                if not isinstance(mappings, dict):
                    continue
                
                # éå†å…·ä½“çš„æ˜ å°„é¡¹
                for arb_key, mapping_data in mappings.items():
                    if not isinstance(mapping_data, dict):
                        continue
                    
                    if not mapping_data.get('approved', False):
                        continue
                    
                    action = mapping_data.get('action', '')
                    if 'create' in action:
                        text_zh = mapping_data.get('text_zh')
                        text_en = mapping_data.get('text_en')
                        
                        if text_zh and arb_key not in self.zh_arb_data:
                            zh_updates[arb_key] = text_zh
                        
                        if text_en and arb_key not in self.en_arb_data:
                            en_updates[arb_key] = text_en
        
        return zh_updates, en_updates
    
    def preview_changes(self):
        """é¢„è§ˆæ‰€æœ‰æ›´æ”¹"""
        print("\nğŸ” === å¢å¼ºç‰ˆæ˜ å°„åº”ç”¨é¢„è§ˆ ===")
        
        # ä»£ç æ›´æ”¹é¢„è§ˆ
        code_changes = self.process_code_replacements()
        print(f"\nğŸ“ === ä»£ç æ›´æ”¹é¢„è§ˆ ===")
        print(f"å°†å¤„ç† {len(code_changes)} ä¸ªæ–‡ä»¶:")
        
        files_needing_import = set()
        
        for change in code_changes:
            print(f"\n  ğŸ“ æ–‡ä»¶: {change['file']}")
            print(f"     åŸæ–‡: \"{change['original']}\"")
            print(f"     æ›¿æ¢: {change['context_access']}.{change['arb_key']}")
            print(f"     ç­–ç•¥: {change['strategy']['widget_type']} ç±»å‹")
            
            if change['import_needed']:
                files_needing_import.add(change['file'])
                print(f"     ğŸ“¦ éœ€è¦æ·»åŠ æœ¬åœ°åŒ–å¯¼å…¥")
        
        if files_needing_import:
            print(f"\nğŸ“¦ === å¯¼å…¥æ·»åŠ é¢„è§ˆ ===")
            print(f"å°†ä¸º {len(files_needing_import)} ä¸ªæ–‡ä»¶æ·»åŠ æœ¬åœ°åŒ–å¯¼å…¥:")
            for file_path in sorted(files_needing_import):
                print(f"  - {file_path}")
        
        # ARBæ›´æ–°é¢„è§ˆ
        zh_updates, en_updates = self.process_arb_updates()
        total_new_keys = len(zh_updates) + len(en_updates)
        
        if total_new_keys > 0:
            print(f"\nğŸŒ === ARBæ›´æ–°é¢„è§ˆ ===")
            print(f"å°†æ·»åŠ  {total_new_keys} ä¸ªæ–°é”®åˆ°ARBæ–‡ä»¶:")
            
            all_keys = set(zh_updates.keys()) | set(en_updates.keys())
            for key in sorted(all_keys):
                print(f"  {key}:")
                if key in zh_updates:
                    print(f"    zh: {zh_updates[key]}")
                if key in en_updates:
                    print(f"    en: {en_updates[key]}")
        
        return len(code_changes) > 0 or total_new_keys > 0
    
    def run_preview(self):
        """è¿è¡Œé¢„è§ˆæ¨¡å¼"""
        if not self.load_mapping_file():
            return False
        
        self.load_arb_files()
        return self.preview_changes()
    
    def apply_changes(self):
        """åº”ç”¨æ‰€æœ‰æ›´æ”¹"""
        print("\nğŸš€ === å¢å¼ºç‰ˆæ˜ å°„åº”ç”¨ ===")
        
        if not self.load_mapping_file():
            return False
        
        self.load_arb_files()
        
        # å¤„ç†ä»£ç æ›´æ”¹
        code_changes = self.process_code_replacements()
        files_changed = self.apply_code_changes(code_changes)
        
        # å¤„ç†ARBæ›´æ–°
        zh_updates, en_updates = self.process_arb_updates()
        arb_files_changed = self.apply_arb_changes(zh_updates, en_updates)
        
        # æŠ¥å‘Šç»“æœ
        print(f"\nâœ… åº”ç”¨å®Œæˆ!")
        if files_changed:
            print(f"ğŸ“ å·²ä¿®æ”¹ {len(files_changed)} ä¸ªä»£ç æ–‡ä»¶")
            print(f"ğŸ“¦ å·²æ·»åŠ å¿…è¦çš„æœ¬åœ°åŒ–å¯¼å…¥")
        if arb_files_changed:
            print(f"ğŸŒ å·²æ›´æ–° {len(arb_files_changed)} ä¸ªARBæ–‡ä»¶")
        
        return True
    
    def apply_arb_changes(self, zh_updates, en_updates):
        """åº”ç”¨ARBæ–‡ä»¶æ›´æ”¹"""
        arb_files_changed = []
        
        # æ›´æ–°ä¸­æ–‡ARB
        if zh_updates:
            for key, value in zh_updates.items():
                self.zh_arb_data[key] = value
            
            if not self.dry_run:
                backup_path = f"{ZH_ARB_PATH}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                if os.path.exists(ZH_ARB_PATH):
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(dict(self.zh_arb_data), f, ensure_ascii=False, indent=2)
                
                with open(ZH_ARB_PATH, 'w', encoding='utf-8') as f:
                    json.dump(dict(self.zh_arb_data), f, ensure_ascii=False, indent=2)
            
            arb_files_changed.append(ZH_ARB_PATH)
        
        # æ›´æ–°è‹±æ–‡ARB
        if en_updates:
            for key, value in en_updates.items():
                self.en_arb_data[key] = value
            
            if not self.dry_run:
                backup_path = f"{EN_ARB_PATH}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                if os.path.exists(EN_ARB_PATH):
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(dict(self.en_arb_data), f, ensure_ascii=False, indent=2)
                
                with open(EN_ARB_PATH, 'w', encoding='utf-8') as f:
                    json.dump(dict(self.en_arb_data), f, ensure_ascii=False, indent=2)
            
            arb_files_changed.append(EN_ARB_PATH)
        
        return arb_files_changed

def find_latest_mapping_file():
    """æŸ¥æ‰¾æœ€æ–°çš„æ˜ å°„æ–‡ä»¶"""
    pattern = "**/multilingual_mapping_*.yaml"
    files = glob.glob(pattern, recursive=True)
    
    if not files:
        print("âŒ æœªæ‰¾åˆ°æ˜ å°„æ–‡ä»¶")
        return None
    
    latest_file = max(files, key=os.path.getmtime)
    return latest_file

def main():
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆå¤šè¯­è¨€æ˜ å°„åº”ç”¨å™¨')
    parser.add_argument('--input', '-i', help='æ˜ å°„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dry-run', '-d', action='store_true', help='å¹²è¿è¡Œæ¨¡å¼ï¼Œåªé¢„è§ˆæ›´æ”¹')
    parser.add_argument('--auto-latest', '-a', action='store_true', help='è‡ªåŠ¨ä½¿ç”¨æœ€æ–°æ˜ å°„æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜ å°„æ–‡ä»¶
    mapping_file = None
    
    if args.auto_latest:
        mapping_file = find_latest_mapping_file()
        if mapping_file:
            print(f"ä½¿ç”¨æœ€æ–°æ˜ å°„æ–‡ä»¶: {mapping_file}")
    elif args.input:
        mapping_file = args.input
    else:
        print("âŒ è¯·æŒ‡å®šæ˜ å°„æ–‡ä»¶è·¯å¾„æˆ–ä½¿ç”¨ --auto-latest é€‰é¡¹")
        return
    
    if not mapping_file or not os.path.exists(mapping_file):
        print(f"âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
        return
    
    # åˆ›å»ºåº”ç”¨å™¨
    applier = EnhancedMappingApplier(mapping_file, dry_run=args.dry_run)
    
    if args.dry_run:
        # é¢„è§ˆæ¨¡å¼
        success = applier.run_preview()
        if success:
            print("\nâœ… é¢„è§ˆå®Œæˆï¼å¦‚æœç¡®è®¤æ— è¯¯ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°æ­£å¼åº”ç”¨æ›´æ”¹ã€‚")
    else:
        # å®é™…åº”ç”¨
        print("âš ï¸  å³å°†åº”ç”¨æ›´æ”¹ï¼Œè¿™å°†ä¿®æ”¹ä»£ç æ–‡ä»¶å’ŒARBæ–‡ä»¶ï¼Œå¹¶æ·»åŠ å¿…è¦çš„å¯¼å…¥ã€‚")
        confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): ")
        if confirm.lower() == 'y':
            applier.apply_changes()
            print("\nğŸ‰ åº”ç”¨å®Œæˆï¼")
        else:
            print("å·²å–æ¶ˆæ“ä½œã€‚")

if __name__ == "__main__":
    main()
