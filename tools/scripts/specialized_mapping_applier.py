#!/usr/bin/env python3
"""
ä¸“ç”¨æ˜ å°„åº”ç”¨å™¨ - å¤„ç†OrderedDictæ ¼å¼å¹¶æ­£ç¡®æ·»åŠ æœ¬åœ°åŒ–å¯¼å…¥
"""

import os
import re
import json
import yaml
from collections import OrderedDict
from datetime import datetime

# é…ç½®å¸¸é‡
CODE_DIR = "lib"
ARB_DIR = "lib/l10n"
ZH_ARB_PATH = os.path.join(ARB_DIR, "app_zh.arb")
EN_ARB_PATH = os.path.join(ARB_DIR, "app_en.arb")

class SpecializedMappingApplier:
    def __init__(self, mapping_file_path, dry_run=True):
        self.mapping_file_path = mapping_file_path
        self.dry_run = dry_run
        self.mapping_data = None
        self.zh_arb_data = OrderedDict()
        self.en_arb_data = OrderedDict()
        
    def load_mapping_file(self):
        """åŠ è½½å¤æ‚æ ¼å¼çš„æ˜ å°„æ–‡ä»¶"""
        try:
            with open(self.mapping_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # é¢„å¤„ç†YAMLå†…å®¹ï¼Œä¿®å¤è¯­æ³•é—®é¢˜
            content = self.preprocess_yaml_content(content)
            
            # ä½¿ç”¨unsafe_loadå¤„ç†OrderedDictæ ¼å¼
            self.mapping_data = yaml.unsafe_load(content)
            print(f"âœ… æˆåŠŸåŠ è½½æ˜ å°„æ–‡ä»¶: {self.mapping_file_path}")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def preprocess_yaml_content(self, content):
        """é¢„å¤„ç†YAMLå†…å®¹ï¼Œä¿®å¤å¸¸è§è¯­æ³•é—®é¢˜"""
        lines = content.split('\n')
        fixed_lines = []
        fixed_count = 0
        
        for line in lines:
            # ä¿®å¤åŒ…å« ${...} å’Œ {...} çš„è¡Œ
            if re.search(r'\$?\{[^}]+\}', line) and ':' in line:
                if ': ' in line and not line.strip().endswith('"') and not line.strip().endswith("'"):
                    key_part, value_part = line.split(': ', 1)
                    # ä¸ºåŒ…å«æ¨¡æ¿è¯­æ³•çš„å€¼æ·»åŠ å¼•å·
                    if re.search(r'\$?\{[^}]+\}', value_part):
                        if not (value_part.startswith('"') and value_part.endswith('"')):
                            if not (value_part.startswith("'") and value_part.endswith("'")):
                                line = f"{key_part}: \"{value_part}\""
                                fixed_count += 1
            
            fixed_lines.append(line)
        
        if fixed_count > 0:
            print(f"ğŸ”§ ä¿®å¤äº† {fixed_count} ä¸ªYAMLè¯­æ³•é—®é¢˜")
        
        return '\n'.join(fixed_lines)
    
    def load_arb_files(self):
        """åŠ è½½ARBæ–‡ä»¶"""
        if os.path.exists(ZH_ARB_PATH):
            with open(ZH_ARB_PATH, 'r', encoding='utf-8') as f:
                self.zh_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        if os.path.exists(EN_ARB_PATH):
            with open(EN_ARB_PATH, 'r', encoding='utf-8') as f:
                self.en_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        print(f"âœ… å·²åŠ è½½ARBæ–‡ä»¶ - ä¸­æ–‡: {len(self.zh_arb_data)} é”®, è‹±æ–‡: {len(self.en_arb_data)} é”®")
    
    def extract_mappings(self):
        """ä»OrderedDictç»“æ„ä¸­æå–æ˜ å°„"""
        mappings = []
        
        def process_ordered_dict(data, level=0):
            if isinstance(data, OrderedDict):
                for key, value in data.items():
                    if isinstance(value, OrderedDict):
                        process_ordered_dict(value, level + 1)
                    elif isinstance(value, dict) and all(k in value for k in ['text_zh', 'file', 'approved']):
                        # è¿™æ˜¯ä¸€ä¸ªæ˜ å°„é¡¹
                        mappings.append({
                            'arb_key': key,
                            'text_zh': value.get('text_zh'),
                            'text_en': value.get('text_en'),
                            'file': value.get('file'),
                            'line': value.get('line', 0),
                            'action': value.get('action'),
                            'approved': value.get('approved', False)
                        })
            elif isinstance(data, list):
                for item in data:
                    process_ordered_dict(item, level)
        
        process_ordered_dict(self.mapping_data)
        return mappings
    
    def analyze_dart_file(self, file_path):
        """åˆ†æDartæ–‡ä»¶ï¼Œæ£€æŸ¥æœ¬åœ°åŒ–çŠ¶æ€"""
        if not os.path.exists(file_path):
            return None
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return {
            'has_material_import': 'package:flutter/material.dart' in content,
            'has_l10n_import': any([
                'package:flutter_gen/gen_l10n/app_localizations.dart' in content,
                'generated/l10n/l10n.dart' in content,
                '../../../generated/l10n.dart' in content
            ]),
            'uses_s_of_context': 'S.of(context)' in content,
            'is_widget_class': 'extends StatelessWidget' in content or 'extends StatefulWidget' in content,
            'content': content
        }
    
    def add_l10n_import(self, content):
        """æ·»åŠ æœ¬åœ°åŒ–å¯¼å…¥"""
        lines = content.split('\n')
        
        # æŸ¥æ‰¾å¯¼å…¥æ’å…¥ä½ç½®
        last_import_index = -1
        for i, line in enumerate(lines):
            if line.strip().startswith('import '):
                last_import_index = i
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰l10nå¯¼å…¥
        has_l10n = any(
            'app_localizations' in line.lower() or 
            'generated/l10n' in line or
            'flutter_gen/gen_l10n' in line
            for line in lines
        )
        
        if not has_l10n:
            # æ·»åŠ æœ¬åœ°åŒ–å¯¼å…¥
            import_line = "import '../../../generated/l10n.dart';"
            insert_pos = last_import_index + 1 if last_import_index >= 0 else 0
            lines.insert(insert_pos, import_line)
            print(f"  ğŸ“¦ æ·»åŠ æœ¬åœ°åŒ–å¯¼å…¥: {import_line}")
        
        return '\n'.join(lines)
    
    def process_mappings(self):
        """å¤„ç†æ˜ å°„ï¼Œç”Ÿæˆä»£ç æ›´æ”¹"""
        mappings = self.extract_mappings()
        
        # è¿‡æ»¤å·²æ‰¹å‡†çš„æ˜ å°„
        approved_mappings = [m for m in mappings if m['approved']]
        
        print(f"\nğŸ“Š æ˜ å°„ç»Ÿè®¡:")
        print(f"  æ€»æ˜ å°„æ•°: {len(mappings)}")
        print(f"  å·²æ‰¹å‡†æ•°: {len(approved_mappings)}")
        
        if not approved_mappings:
            print("âš ï¸  æ²¡æœ‰å·²æ‰¹å‡†çš„æ˜ å°„é¡¹ï¼Œè¯·åœ¨æ˜ å°„æ–‡ä»¶ä¸­è®¾ç½® approved: true")
            return [], {}
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„
        files_to_process = {}
        arb_updates = {'zh': {}, 'en': {}}
        
        for mapping in approved_mappings:
            file_path = mapping['file']
            
            # æ ‡å‡†åŒ–æ–‡ä»¶è·¯å¾„
            if '\\' in file_path:
                file_path = file_path.replace('\\', '/')
            if not file_path.startswith('lib/'):
                file_path = 'lib/' + file_path.lstrip('/')
            
            if file_path not in files_to_process:
                files_to_process[file_path] = []
            
            files_to_process[file_path].append(mapping)
            
            # æ”¶é›†ARBæ›´æ–°
            if 'create' in mapping.get('action', ''):
                arb_key = mapping['arb_key']
                if mapping['text_zh'] and arb_key not in self.zh_arb_data:
                    arb_updates['zh'][arb_key] = mapping['text_zh']
                if mapping['text_en'] and arb_key not in self.en_arb_data:
                    arb_updates['en'][arb_key] = mapping['text_en']
        
        return files_to_process, arb_updates
    
    def preview_changes(self):
        """é¢„è§ˆæ‰€æœ‰æ›´æ”¹"""
        print("\nğŸ” === ä¸“ç”¨æ˜ å°„åº”ç”¨é¢„è§ˆ ===")
        
        files_to_process, arb_updates = self.process_mappings()
        
        if not files_to_process:
            return False
        
        # é¢„è§ˆæ–‡ä»¶æ›´æ”¹
        print(f"\nğŸ“ === ä»£ç æ–‡ä»¶æ›´æ”¹é¢„è§ˆ ===")
        print(f"å°†å¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶:")
        
        for file_path, mappings in files_to_process.items():
            print(f"\n  ğŸ“ æ–‡ä»¶: {file_path}")
            
            # åˆ†ææ–‡ä»¶
            analysis = self.analyze_dart_file(file_path)
            if analysis:
                print(f"     æœ¬åœ°åŒ–å¯¼å…¥: {'âœ…' if analysis['has_l10n_import'] else 'âŒ éœ€è¦æ·»åŠ '}")
                print(f"     Widgetç±»: {'âœ…' if analysis['is_widget_class'] else 'âš ï¸'}")
                print(f"     ä½¿ç”¨S.of(context): {'âœ…' if analysis['uses_s_of_context'] else 'âš ï¸'}")
            else:
                print(f"     âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨")
                continue
            
            print(f"     å°†æ›¿æ¢ {len(mappings)} ä¸ªç¡¬ç¼–ç æ–‡æœ¬:")
            for mapping in mappings:
                original = mapping['text_zh'] or mapping['text_en']
                replacement = f"S.of(context).{mapping['arb_key']}"
                print(f"       ç¬¬ {mapping['line']} è¡Œ: \"{original}\" -> {replacement}")
        
        # é¢„è§ˆARBæ›´æ–°
        total_arb_updates = len(arb_updates['zh']) + len(arb_updates['en'])
        if total_arb_updates > 0:
            print(f"\nğŸŒ === ARBæ–‡ä»¶æ›´æ–°é¢„è§ˆ ===")
            print(f"å°†æ·»åŠ  {total_arb_updates} ä¸ªæ–°é”®:")
            
            all_keys = set(arb_updates['zh'].keys()) | set(arb_updates['en'].keys())
            for key in sorted(all_keys):
                print(f"  {key}:")
                if key in arb_updates['zh']:
                    print(f"    zh: {arb_updates['zh'][key]}")
                if key in arb_updates['en']:
                    print(f"    en: {arb_updates['en'][key]}")
        
        return True
    
    def apply_changes(self):
        """åº”ç”¨æ‰€æœ‰æ›´æ”¹"""
        print("\nğŸš€ === åº”ç”¨æ›´æ”¹ ===")
        
        files_to_process, arb_updates = self.process_mappings()
        
        if not files_to_process:
            return False
        
        files_changed = 0
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for file_path, mappings in files_to_process.items():
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {file_path}")
            
            # åˆ†ææ–‡ä»¶
            analysis = self.analyze_dart_file(file_path)
            if not analysis:
                print(f"  âš ï¸  è·³è¿‡ï¼šæ–‡ä»¶ä¸å­˜åœ¨")
                continue
            
            content = analysis['content']
            
            # æ·»åŠ å¯¼å…¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not analysis['has_l10n_import']:
                content = self.add_l10n_import(content)
            
            # æ›¿æ¢ç¡¬ç¼–ç æ–‡æœ¬
            changes_made = 0
            for mapping in mappings:
                original_text = mapping['text_zh'] or mapping['text_en']
                arb_key = mapping['arb_key']
                replacement = f"S.of(context).{arb_key}"
                
                # å°è¯•ä¸åŒçš„å¼•å·æ ¼å¼
                patterns = [f'"{original_text}"', f"'{original_text}'"]
                
                for pattern in patterns:
                    if pattern in content:
                        content = content.replace(pattern, replacement)
                        print(f"  âœ… æ›¿æ¢: {pattern} -> {replacement}")
                        changes_made += 1
                        break
                else:
                    print(f"  âš ï¸  æœªæ‰¾åˆ°: {original_text}")
            
            # ä¿å­˜æ–‡ä»¶
            if changes_made > 0 or not analysis['has_l10n_import']:
                if not self.dry_run:
                    # å¤‡ä»½åŸæ–‡ä»¶
                    backup_path = f"{file_path}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        f.write(analysis['content'])
                    
                    # å†™å…¥æ–°å†…å®¹
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                
                files_changed += 1
                print(f"  âœ… æ–‡ä»¶å·²{'é¢„è§ˆ' if self.dry_run else 'æ›´æ–°'}")
        
        # å¤„ç†ARBæ–‡ä»¶æ›´æ–°
        if arb_updates['zh'] or arb_updates['en']:
            print(f"\nğŸŒ æ›´æ–°ARBæ–‡ä»¶:")
            
            if arb_updates['zh']:
                print(f"  ä¸­æ–‡ARB: æ·»åŠ  {len(arb_updates['zh'])} ä¸ªé”®")
                if not self.dry_run:
                    self.zh_arb_data.update(arb_updates['zh'])
                    with open(ZH_ARB_PATH, 'w', encoding='utf-8') as f:
                        json.dump(dict(self.zh_arb_data), f, ensure_ascii=False, indent=2)
            
            if arb_updates['en']:
                print(f"  è‹±æ–‡ARB: æ·»åŠ  {len(arb_updates['en'])} ä¸ªé”®")
                if not self.dry_run:
                    self.en_arb_data.update(arb_updates['en'])
                    with open(EN_ARB_PATH, 'w', encoding='utf-8') as f:
                        json.dump(dict(self.en_arb_data), f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼{'é¢„è§ˆäº†' if self.dry_run else 'ä¿®æ”¹äº†'} {files_changed} ä¸ªæ–‡ä»¶")
        return True
    
    def run(self):
        """è¿è¡Œåº”ç”¨å™¨"""
        if not self.load_mapping_file():
            return False
        
        self.load_arb_files()
        
        if self.dry_run:
            success = self.preview_changes()
            if success:
                print("\nâœ… é¢„è§ˆå®Œæˆï¼å¦‚æœç¡®è®¤æ— è¯¯ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°æ­£å¼åº”ç”¨æ›´æ”¹ã€‚")
        else:
            success = self.apply_changes()
        
        return success

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸“ç”¨æ˜ å°„åº”ç”¨å™¨')
    parser.add_argument('--input', '-i', required=True, help='æ˜ å°„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dry-run', '-d', action='store_true', default=True, help='å¹²è¿è¡Œæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰')
    parser.add_argument('--apply', action='store_true', help='å®é™…åº”ç”¨æ›´æ”¹')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    # ç¡®å®šæ˜¯å¦ä¸ºå¹²è¿è¡Œ
    dry_run = not args.apply
    if dry_run:
        print("ğŸ” è¿è¡Œé¢„è§ˆæ¨¡å¼")
    else:
        print("âš ï¸  è¿è¡Œå®é™…åº”ç”¨æ¨¡å¼")
    
    applier = SpecializedMappingApplier(args.input, dry_run=dry_run)
    
    if not dry_run:
        confirm = input("ç¡®è®¤è¦åº”ç”¨æ›´æ”¹å—ï¼Ÿ(y/N): ")
        if confirm.lower() != 'y':
            print("å·²å–æ¶ˆæ“ä½œ")
            return
    
    applier.run()

if __name__ == "__main__":
    main()
