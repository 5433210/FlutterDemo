#!/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆæœªä½¿ç”¨æ–‡ä»¶åˆ†æå·¥å…·
æä¾›æ›´é«˜ç²¾åº¦çš„æ–‡ä»¶ä½¿ç”¨æƒ…å†µæ£€æµ‹
"""

import os
import re
import json
from pathlib import Path
from typing import Set, Dict, List, Tuple, Optional
from urllib.parse import unquote

class ImprovedUnusedAnalyzer:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root).resolve()
        self.lib_dir = self.project_root / 'lib'
        self.test_dir = self.project_root / 'test'
        
        # å­˜å‚¨åˆ†æç»“æœ
        self.all_files: Set[str] = set()
        self.import_relationships: Dict[str, Set[str]] = {}
        self.used_files: Set[str] = set()
        self.file_info: Dict[str, dict] = {}
        
        # æ’é™¤æ¨¡å¼
        self.excluded_patterns = [
            r'\.g\.dart$',      # ä»£ç ç”Ÿæˆæ–‡ä»¶
            r'\.freezed\.dart$', # Freezedç”Ÿæˆæ–‡ä»¶
        ]
        
        # å…¥å£æ–‡ä»¶æ¨¡å¼
        self.entry_patterns = [
            'lib/main.dart',
            'lib/app.dart',
            'lib/presentation/app.dart',
            'lib/routes/app_routes.dart',
            'lib/providers.dart',
        ]
        
        # ç‰¹æ®Šæ–‡ä»¶æ¨¡å¼ï¼ˆé€šå¸¸è¢«åŠ¨æ€å¼•ç”¨ï¼‰
        self.special_patterns = [
            r'.*provider.*\.dart$',    # Provideræ–‡ä»¶
            r'.*route.*\.dart$',       # è·¯ç”±æ–‡ä»¶
            r'.*navigation.*\.dart$',  # å¯¼èˆªæ–‡ä»¶
            r'.*service.*\.dart$',     # æœåŠ¡æ–‡ä»¶
            r'.*repository.*\.dart$',  # ä»“åº“æ–‡ä»¶
            r'.*mixin.*\.dart$',       # Mixinæ–‡ä»¶
            r'.*extension.*\.dart$',   # æ‰©å±•æ–‡ä»¶
        ]
    
    def scan_all_files(self) -> None:
        """æ‰«ææ‰€æœ‰Dartæ–‡ä»¶å¹¶æ”¶é›†åŸºæœ¬ä¿¡æ¯"""
        print("ğŸ” æ‰«ææ‰€æœ‰Dartæ–‡ä»¶...")
        
        # æ‰«ælibç›®å½•
        lib_files = 0
        if self.lib_dir.exists():
            for dart_file in self.lib_dir.rglob('*.dart'):
                if not self._is_excluded_file(dart_file):
                    rel_path = str(dart_file.relative_to(self.project_root)).replace('\\', '/')
                    self.all_files.add(rel_path)
                    self.file_info[rel_path] = {
                        'size': dart_file.stat().st_size,
                        'is_empty': dart_file.stat().st_size < 50,  # è®¤ä¸ºå°äº50å­—èŠ‚çš„æ–‡ä»¶ä¸ºç©º
                        'is_special': self._is_special_file(rel_path),
                        'absolute_path': dart_file
                    }
                    lib_files += 1
        
        # æ‰«ætestç›®å½•
        test_files = 0
        if self.test_dir.exists():
            for dart_file in self.test_dir.rglob('*.dart'):
                rel_path = str(dart_file.relative_to(self.project_root)).replace('\\', '/')
                self.all_files.add(rel_path)
                self.file_info[rel_path] = {
                    'size': dart_file.stat().st_size,
                    'is_empty': dart_file.stat().st_size < 50,
                    'is_special': False,
                    'is_test': True,
                    'absolute_path': dart_file
                }
                test_files += 1
        
        print(f"   æ€»æœ‰æ•ˆæ–‡ä»¶æ•°: {len(self.all_files)}")
        print(f"   libæ–‡ä»¶: {lib_files}, testæ–‡ä»¶: {test_files}")
    
    def _is_excluded_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
        file_str = str(file_path)
        return any(re.search(pattern, file_str) for pattern in self.excluded_patterns)
    
    def _is_special_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹æ®Šæ–‡ä»¶ï¼ˆé€šå¸¸è¢«åŠ¨æ€å¼•ç”¨ï¼‰"""
        return any(re.search(pattern, file_path, re.IGNORECASE) for pattern in self.special_patterns)
    
    def analyze_imports(self) -> None:
        """åˆ†ææ‰€æœ‰æ–‡ä»¶çš„å¯¼å…¥å…³ç³»"""
        print("ğŸ“š åˆ†æå¯¼å…¥å…³ç³»...")
        
        for file_path in self.all_files:
            full_path = self.file_info[file_path]['absolute_path']
            imports = self._extract_imports_improved(full_path, file_path)
            self.import_relationships[file_path] = imports
        
        print(f"   åˆ†æäº† {len(self.import_relationships)} ä¸ªæ–‡ä»¶çš„å¯¼å…¥å…³ç³»")
        
        # ç»Ÿè®¡å¯¼å…¥æ•°é‡
        total_imports = sum(len(imports) for imports in self.import_relationships.values())
        print(f"   å‘ç° {total_imports} ä¸ªå¯¼å…¥å…³ç³»")
    
    def _extract_imports_improved(self, file_path: Path, relative_path: str) -> Set[str]:
        """æ”¹è¿›çš„å¯¼å…¥æå–æ–¹æ³•"""
        imports = set()
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"   è­¦å‘Š: è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return imports
        
        # ç§»é™¤æ³¨é‡Šå’Œå­—ç¬¦ä¸²å­—é¢é‡ï¼Œé¿å…è¯¯æ£€æµ‹
        content = self._remove_comments_and_strings(content)
        
        # å¤šç§å¯¼å…¥æ¨¡å¼
        import_patterns = [
            r"import\s+['\"]([^'\"]+)['\"]",     # import 'path'
            r"export\s+['\"]([^'\"]+)['\"]",     # export 'path'
            r"part\s+['\"]([^'\"]+)['\"]",       # part 'path'
            r"part\s+of\s+['\"]([^'\"]+)['\"]",  # part of 'path'
        ]
        
        for pattern in import_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                resolved_import = self._resolve_import_path(match, relative_path)
                if resolved_import:
                    imports.add(resolved_import)
        
        return imports
    
    def _remove_comments_and_strings(self, content: str) -> str:
        """ç§»é™¤æ³¨é‡Šå’Œå­—ç¬¦ä¸²å­—é¢é‡ï¼Œé¿å…åœ¨æ³¨é‡Šä¸­çš„importè¢«è¯¯æ£€æµ‹"""
        # ç®€å•çš„æ³¨é‡Šå’Œå­—ç¬¦ä¸²ç§»é™¤ï¼ˆä¸å®Œå…¨ç²¾ç¡®ï¼Œä½†è¶³å¤Ÿç”¨ï¼‰
        lines = content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # ç§»é™¤å•è¡Œæ³¨é‡Š
            if '//' in line:
                line = line[:line.find('//')]
            
            # ç§»é™¤å¤šè¡Œæ³¨é‡Šï¼ˆç®€å•å¤„ç†ï¼‰
            if '/*' in line and '*/' in line:
                start = line.find('/*')
                end = line.find('*/', start) + 2
                line = line[:start] + line[end:]
            
            cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def _resolve_import_path(self, import_path: str, current_file: str) -> Optional[str]:
        """è§£æå¯¼å…¥è·¯å¾„ä¸ºé¡¹ç›®å†…çš„ç›¸å¯¹è·¯å¾„"""
        try:
            # å¤„ç†package:å¯¼å…¥
            if import_path.startswith('package:demo/'):
                lib_path = import_path.replace('package:demo/', 'lib/')
                if lib_path in self.all_files:
                    return lib_path
            
            # å¤„ç†dart:å¯¼å…¥ï¼ˆå¿½ç•¥ï¼‰
            elif import_path.startswith('dart:'):
                return None
            
            # å¤„ç†å¤–éƒ¨packageå¯¼å…¥ï¼ˆå¿½ç•¥ï¼‰
            elif import_path.startswith('package:') and not import_path.startswith('package:demo/'):
                return None
            
            # å¤„ç†ç›¸å¯¹å¯¼å…¥
            elif import_path.startswith('.'):
                current_dir = Path(current_file).parent
                target_path = (current_dir / import_path).resolve()
                
                # è½¬æ¢ä¸ºç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
                try:
                    rel_target = str(target_path.relative_to(self.project_root)).replace('\\', '/')
                    if rel_target in self.all_files:
                        return rel_target
                except ValueError:
                    # è·¯å¾„ä¸åœ¨é¡¹ç›®å†…
                    pass
            
            # å¤„ç†ç»å¯¹å¯¼å…¥ï¼ˆç›¸å¯¹äºlibç›®å½•ï¼‰
            else:
                # å°è¯•ä½œä¸ºlibç›®å½•ä¸‹çš„æ–‡ä»¶
                lib_path = f"lib/{import_path}"
                if lib_path in self.all_files:
                    return lib_path
                
                # å°è¯•æ·»åŠ .dartæ‰©å±•å
                if not import_path.endswith('.dart'):
                    lib_path_dart = f"lib/{import_path}.dart"
                    if lib_path_dart in self.all_files:
                        return lib_path_dart
        
        except Exception:
            pass
        
        return None
    
    def mark_used_files(self) -> None:
        """æ ‡è®°è¢«ä½¿ç”¨çš„æ–‡ä»¶"""
        print("ğŸ¯ æ ‡è®°æ–‡ä»¶ä½¿ç”¨æƒ…å†µ...")
        
        # 1. æ ‡è®°å…¥å£æ–‡ä»¶
        entry_count = 0
        for entry_pattern in self.entry_patterns:
            if entry_pattern in self.all_files:
                self.used_files.add(entry_pattern)
                entry_count += 1
        print(f"   å‘ç° {entry_count} ä¸ªå…¥å£æ–‡ä»¶")
        
        # 2. æ ‡è®°æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ä¸ºå·²ä½¿ç”¨
        test_count = 0
        for file_path in self.all_files:
            if file_path.startswith('test/'):
                self.used_files.add(file_path)
                test_count += 1
        print(f"   æ ‡è®° {test_count} ä¸ªæµ‹è¯•æ–‡ä»¶ä¸ºå·²ä½¿ç”¨")
        
        # 3. æ ‡è®°ç‰¹æ®Šæ–‡ä»¶
        special_count = 0
        for file_path in self.all_files:
            if self.file_info[file_path].get('is_special', False):
                self.used_files.add(file_path)
                special_count += 1
        print(f"   æ ‡è®° {special_count} ä¸ªç‰¹æ®Šæ–‡ä»¶ä¸ºå·²ä½¿ç”¨")
        
        # 4. é€’å½’æ ‡è®°è¢«å¯¼å…¥çš„æ–‡ä»¶
        initial_used = len(self.used_files)
        changed = True
        iterations = 0
        max_iterations = 100  # é˜²æ­¢æ— é™å¾ªç¯
        
        while changed and iterations < max_iterations:
            changed = False
            iterations += 1
            old_count = len(self.used_files)
            
            # éå†å·²ä½¿ç”¨çš„æ–‡ä»¶ï¼Œæ ‡è®°å®ƒä»¬å¯¼å…¥çš„æ–‡ä»¶
            for used_file in list(self.used_files):
                if used_file in self.import_relationships:
                    for imported_file in self.import_relationships[used_file]:
                        if imported_file not in self.used_files:
                            self.used_files.add(imported_file)
                            changed = True
            
            new_count = len(self.used_files)
            if new_count > old_count:
                print(f"     ç¬¬{iterations}è½®: æ–°å¢ {new_count - old_count} ä¸ªä½¿ç”¨æ–‡ä»¶")
        
        final_used = len(self.used_files)
        print(f"   ç»è¿‡ {iterations} è½®è¿­ä»£ï¼Œä» {initial_used} å¢åŠ åˆ° {final_used} ä¸ªå·²ä½¿ç”¨æ–‡ä»¶")
    
    def analyze_unused_files(self) -> Dict[str, List[dict]]:
        """åˆ†ææœªä½¿ç”¨çš„æ–‡ä»¶ï¼ŒæŒ‰ä¼˜å…ˆçº§åˆ†ç±»"""
        print("ğŸ“Š åˆ†ææœªä½¿ç”¨æ–‡ä»¶...")
        
        unused_analysis = {
            'safe_to_delete': [],      # å®‰å…¨åˆ é™¤
            'likely_unused': [],       # å¯èƒ½æœªä½¿ç”¨
            'review_needed': [],       # éœ€è¦äººå·¥å®¡æŸ¥
            'empty_files': []          # ç©ºæ–‡ä»¶
        }
        
        for file_path in self.all_files:
            if file_path.startswith('lib/') and file_path not in self.used_files:
                file_info = self.file_info[file_path]
                
                file_data = {
                    'path': file_path,
                    'size_kb': file_info['size'] / 1024,
                    'size_bytes': file_info['size'],
                    'is_empty': file_info['is_empty'],
                    'is_special': file_info['is_special']
                }
                
                # åˆ†ç±»é€»è¾‘
                if file_info['is_empty']:
                    unused_analysis['empty_files'].append(file_data)
                elif file_info['is_special']:
                    unused_analysis['review_needed'].append(file_data)
                elif file_info['size'] < 1000:  # å°äº1KBçš„æ–‡ä»¶
                    unused_analysis['likely_unused'].append(file_data)
                else:
                    unused_analysis['safe_to_delete'].append(file_data)
        
        # æŒ‰å¤§å°æ’åº
        for category in unused_analysis.values():
            category.sort(key=lambda x: x['size_bytes'])
        
        return unused_analysis
    
    def cross_validate_sample(self, sample_files: List[str], sample_size: int = 20) -> Dict:
        """äº¤å‰éªŒè¯æ ·æœ¬æ–‡ä»¶"""
        print(f"ğŸ”¬ äº¤å‰éªŒè¯å‰{sample_size}ä¸ªæ–‡ä»¶...")
        
        validation_results = {
            'checked': 0,
            'confirmed_unused': 0,
            'false_positives': 0,
            'false_positive_files': []
        }
        
        for i, file_path in enumerate(sample_files[:sample_size]):
            validation_results['checked'] += 1
            
            # åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­æœç´¢å¯¹æ­¤æ–‡ä»¶çš„å¼•ç”¨
            is_referenced = False
            references = []
            
            file_name = Path(file_path).stem
            
            for check_file in self.all_files:
                if check_file == file_path:
                    continue
                
                try:
                    with open(self.file_info[check_file]['absolute_path'], 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # æ£€æŸ¥å¤šç§å¼•ç”¨æ–¹å¼
                    if (file_path in content or 
                        file_name in content or
                        f"'{file_path}'" in content or
                        f'"{file_path}"' in content):
                        is_referenced = True
                        references.append(check_file)
                        break
                        
                except Exception:
                    continue
            
            if is_referenced:
                validation_results['false_positives'] += 1
                validation_results['false_positive_files'].append({
                    'file': file_path,
                    'references': references[:3]  # åªä¿ç•™å‰3ä¸ªå¼•ç”¨
                })
            else:
                validation_results['confirmed_unused'] += 1
        
        return validation_results
    
    def generate_detailed_report(self) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
        unused_analysis = self.analyze_unused_files()
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_lib_files = len([f for f in self.all_files if f.startswith('lib/')])
        total_unused = sum(len(category) for category in unused_analysis.values())
        used_files = total_lib_files - total_unused
        
        # äº¤å‰éªŒè¯
        all_unused = []
        for category in unused_analysis.values():
            all_unused.extend([item['path'] for item in category])
        
        validation = self.cross_validate_sample(all_unused, min(30, len(all_unused)))
        
        # ç”ŸæˆæŠ¥å‘Š
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ğŸ“Š æ”¹è¿›ç‰ˆæœªä½¿ç”¨æ–‡ä»¶åˆ†ææŠ¥å‘Š")
        report_lines.append("=" * 80)
        report_lines.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        report_lines.append("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        report_lines.append(f"   æ€»libæ–‡ä»¶æ•°: {total_lib_files}")
        report_lines.append(f"   å·²ä½¿ç”¨æ–‡ä»¶: {used_files} ({used_files/total_lib_files*100:.1f}%)")
        report_lines.append(f"   æœªä½¿ç”¨æ–‡ä»¶: {total_unused} ({total_unused/total_lib_files*100:.1f}%)")
        report_lines.append("")
        
        # äº¤å‰éªŒè¯ç»“æœ
        if validation['checked'] > 0:
            accuracy = (validation['confirmed_unused'] / validation['checked']) * 100
            report_lines.append("ğŸ”¬ äº¤å‰éªŒè¯ç»“æœ:")
            report_lines.append(f"   éªŒè¯æ ·æœ¬: {validation['checked']}ä¸ªæ–‡ä»¶")
            report_lines.append(f"   ç¡®è®¤æœªä½¿ç”¨: {validation['confirmed_unused']}ä¸ª")
            report_lines.append(f"   è¯¯æŠ¥: {validation['false_positives']}ä¸ª")
            report_lines.append(f"   é¢„ä¼°å‡†ç¡®ç‡: {accuracy:.1f}%")
            report_lines.append("")
        
        # åˆ†ç±»ç»Ÿè®¡
        report_lines.append("ğŸ“‚ æœªä½¿ç”¨æ–‡ä»¶åˆ†ç±»:")
        for category, items in unused_analysis.items():
            if items:
                total_size = sum(item['size_kb'] for item in items)
                report_lines.append(f"   {self._get_category_name(category)}: {len(items)}ä¸ªæ–‡ä»¶ ({total_size:.1f}KB)")
        report_lines.append("")
        
        # åˆ é™¤å»ºè®®
        report_lines.append("ğŸ¯ åˆ é™¤å»ºè®®:")
        if unused_analysis['empty_files']:
            report_lines.append(f"   âœ… ç«‹å³åˆ é™¤ç©ºæ–‡ä»¶: {len(unused_analysis['empty_files'])}ä¸ª")
        if unused_analysis['safe_to_delete']:
            report_lines.append(f"   âš ï¸  å®¡æŸ¥ååˆ é™¤: {len(unused_analysis['safe_to_delete'])}ä¸ª")
        if unused_analysis['likely_unused']:
            report_lines.append(f"   ğŸ” ä»”ç»†æ£€æŸ¥: {len(unused_analysis['likely_unused'])}ä¸ª")
        if unused_analysis['review_needed']:
            report_lines.append(f"   âŒ éœ€è¦äººå·¥å®¡æŸ¥: {len(unused_analysis['review_needed'])}ä¸ª")
        report_lines.append("")
        
        # è¯¦ç»†åˆ—è¡¨ï¼ˆåªæ˜¾ç¤ºéƒ¨åˆ†ï¼‰
        for category, items in unused_analysis.items():
            if items:
                report_lines.append(f"ğŸ“‹ {self._get_category_name(category)} (æ˜¾ç¤ºå‰10ä¸ª):")
                for item in items[:10]:
                    report_lines.append(f"   - {item['path']} ({item['size_kb']:.1f}KB)")
                if len(items) > 10:
                    report_lines.append(f"   ... è¿˜æœ‰{len(items)-10}ä¸ªæ–‡ä»¶")
                report_lines.append("")
        
        return "\n".join(report_lines)
    
    def _get_category_name(self, category: str) -> str:
        """è·å–åˆ†ç±»çš„ä¸­æ–‡åç§°"""
        names = {
            'safe_to_delete': 'å®‰å…¨åˆ é™¤',
            'likely_unused': 'å¯èƒ½æœªä½¿ç”¨',
            'review_needed': 'éœ€è¦å®¡æŸ¥',
            'empty_files': 'ç©ºæ–‡ä»¶'
        }
        return names.get(category, category)

def main():
    """ä¸»å‡½æ•°"""
    project_root = os.getcwd()
    print(f"ğŸš€ å¯åŠ¨æ”¹è¿›ç‰ˆæœªä½¿ç”¨æ–‡ä»¶åˆ†æå™¨")
    print(f"ğŸ“ é¡¹ç›®è·¯å¾„: {project_root}")
    print()
    
    analyzer = ImprovedUnusedAnalyzer(project_root)
    
    # æ‰§è¡Œåˆ†æ
    analyzer.scan_all_files()
    analyzer.analyze_imports()
    analyzer.mark_used_files()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_detailed_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = Path(project_root) / 'tools' / 'reports' / 'improved_unused_analysis.txt'
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    # ä¿å­˜è¯¦ç»†æ•°æ®
    unused_analysis = analyzer.analyze_unused_files()
    json_path = Path(project_root) / 'tools' / 'reports' / 'improved_unused_analysis.json'
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_lib_files': len([f for f in analyzer.all_files if f.startswith('lib/')]),
                'used_files': len([f for f in analyzer.used_files if f.startswith('lib/')]),
                'unused_by_category': {cat: len(items) for cat, items in unused_analysis.items()}
            },
            'unused_analysis': unused_analysis,
            'validation': analyzer.cross_validate_sample([item['path'] for category in unused_analysis.values() for item in category], 30)
        }, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    print(f"ğŸ“„ JSONæ•°æ®å·²ä¿å­˜åˆ°: {json_path}")

if __name__ == "__main__":
    main() 