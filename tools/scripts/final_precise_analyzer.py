#!/usr/bin/env python3
"""
æœ€ç»ˆé«˜ç²¾åº¦æœªä½¿ç”¨æ–‡ä»¶åˆ†æå·¥å…·
è¿›ä¸€æ­¥æå‡å‡†ç¡®æ€§ï¼Œå‡å°‘è¯¯æŠ¥
"""

import os
import re
import json
from pathlib import Path
from typing import Set, Dict, List, Optional, Tuple

class FinalPreciseAnalyzer:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root).resolve()
        self.lib_dir = self.project_root / 'lib'
        
        # æ•°æ®å­˜å‚¨
        self.all_files: Set[str] = set()
        self.imports: Dict[str, Set[str]] = {}
        self.exports: Dict[str, Set[str]] = {}  # æ–°å¢ï¼šè·Ÿè¸ªexport
        self.used_files: Set[str] = set()
        self.file_info: Dict[str, dict] = {}
        
        # å…¥å£æ–‡ä»¶ï¼ˆä¸¥æ ¼è¯†åˆ«ï¼‰
        self.entry_files = [
            'lib/main.dart',
            'lib/app.dart',
            'lib/presentation/app.dart'
        ]
        
        # é‡è¦çš„æ–‡ä»¶ç±»å‹ï¼ˆä¿å®ˆæ ‡è®°ä¸ºå·²ä½¿ç”¨ï¼‰
        self.important_patterns = [
            r'provider.*\.dart$',
            r'.*_provider\.dart$',
            r'service.*\.dart$',
            r'.*_service\.dart$',
            r'repository.*\.dart$',
            r'.*_repository\.dart$',
            r'route.*\.dart$',
            r'.*_route.*\.dart$',
            r'navigation.*\.dart$',
            r'mixin.*\.dart$',
            r'extension.*\.dart$',
            r'config.*\.dart$',
            r'constants?\.dart$',
            r'theme.*\.dart$',
            r'style.*\.dart$'
        ]
        
        # å¯èƒ½åŠ¨æ€å¼•ç”¨çš„æ–‡ä»¶æ¨¡å¼
        self.dynamic_patterns = [
            r'.*_screen\.dart$',
            r'.*_page\.dart$',
            r'.*_dialog\.dart$',
            r'.*_widget\.dart$',
            r'.*model.*\.dart$',
            r'.*entity.*\.dart$'
        ]
    
    def scan_files(self):
        """æ‰«ææ‰€æœ‰æœ‰æ•ˆæ–‡ä»¶"""
        print("ğŸ” æ‰«æDartæ–‡ä»¶...")
        
        for dart_file in self.lib_dir.rglob('*.dart'):
            # æ’é™¤ç”Ÿæˆæ–‡ä»¶
            if dart_file.name.endswith(('.g.dart', '.freezed.dart')):
                continue
            
            rel_path = str(dart_file.relative_to(self.project_root)).replace('\\', '/')
            self.all_files.add(rel_path)
            
            stat = dart_file.stat()
            self.file_info[rel_path] = {
                'size': stat.st_size,
                'is_empty': stat.st_size < 50,
                'is_important': self._is_important_file(rel_path),
                'is_dynamic': self._is_dynamic_file(rel_path),
                'path_obj': dart_file
            }
        
        print(f"   å‘ç° {len(self.all_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
    
    def _is_important_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡è¦æ–‡ä»¶ï¼ˆé€šå¸¸è¢«é—´æ¥å¼•ç”¨ï¼‰"""
        file_lower = file_path.lower()
        return any(re.search(pattern, file_lower) for pattern in self.important_patterns)
    
    def _is_dynamic_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯èƒ½è¢«åŠ¨æ€å¼•ç”¨"""
        file_lower = file_path.lower()
        return any(re.search(pattern, file_lower) for pattern in self.dynamic_patterns)
    
    def analyze_dependencies(self):
        """åˆ†ææ–‡ä»¶ä¾èµ–å…³ç³»"""
        print("ğŸ“š åˆ†ææ–‡ä»¶ä¾èµ–...")
        
        for rel_path in self.all_files:
            imports, exports = self._extract_dependencies(rel_path)
            self.imports[rel_path] = imports
            self.exports[rel_path] = exports
        
        total_imports = sum(len(imports) for imports in self.imports.values())
        total_exports = sum(len(exports) for exports in self.exports.values())
        print(f"   è§£æ {total_imports} ä¸ªå¯¼å…¥ï¼Œ{total_exports} ä¸ªå¯¼å‡º")
    
    def _extract_dependencies(self, rel_path: str) -> Tuple[Set[str], Set[str]]:
        """æå–å¯¼å…¥å’Œå¯¼å‡ºä¾èµ–"""
        imports = set()
        exports = set()
        
        file_path = self.file_info[rel_path]['path_obj']
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception:
            return imports, exports
        
        # æ¸…ç†æ³¨é‡Š
        content = self._clean_content(content)
        
        # æå–import
        import_pattern = r"import\s+['\"]([^'\"]+)['\"]"
        for match in re.findall(import_pattern, content):
            resolved = self._resolve_path(match, rel_path)
            if resolved:
                imports.add(resolved)
        
        # æå–export  
        export_pattern = r"export\s+['\"]([^'\"]+)['\"]"
        for match in re.findall(export_pattern, content):
            resolved = self._resolve_path(match, rel_path)
            if resolved:
                exports.add(resolved)
        
        # æå–part
        part_pattern = r"part\s+['\"]([^'\"]+)['\"]"
        for match in re.findall(part_pattern, content):
            resolved = self._resolve_path(match, rel_path)
            if resolved:
                imports.add(resolved)
        
        return imports, exports
    
    def _clean_content(self, content: str) -> str:
        """æ¸…ç†å†…å®¹ï¼Œç§»é™¤æ³¨é‡Šå’Œå­—ç¬¦ä¸²å­—é¢é‡"""
        # ç®€åŒ–ç‰ˆæ¸…ç†
        lines = []
        in_multiline_comment = False
        
        for line in content.split('\n'):
            # å¤„ç†å¤šè¡Œæ³¨é‡Š
            if '/*' in line and '*/' not in line:
                in_multiline_comment = True
                line = line[:line.find('/*')]
            elif '*/' in line and in_multiline_comment:
                in_multiline_comment = False
                line = line[line.find('*/') + 2:]
            elif in_multiline_comment:
                continue
            
            # ç§»é™¤å•è¡Œæ³¨é‡Š
            if '//' in line:
                line = line[:line.find('//')]
            
            lines.append(line)
        
        return '\n'.join(lines)
    
    def _resolve_path(self, import_str: str, current_file: str) -> Optional[str]:
        """è§£æå¯¼å…¥è·¯å¾„"""
        # package:demo/ å¯¼å…¥
        if import_str.startswith('package:demo/'):
            target = import_str.replace('package:demo/', 'lib/')
            return target if target in self.all_files else None
        
        # å¤–éƒ¨åŒ…å¯¼å…¥ï¼ˆå¿½ç•¥ï¼‰
        if import_str.startswith('package:') or import_str.startswith('dart:'):
            return None
        
        # ç›¸å¯¹è·¯å¾„å¯¼å…¥
        if import_str.startswith('.'):
            try:
                current_dir = Path(current_file).parent
                resolved_path = (current_dir / import_str).resolve()
                rel_target = str(resolved_path.relative_to(self.project_root)).replace('\\', '/')
                return rel_target if rel_target in self.all_files else None
            except:
                return None
        
        # ç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºlibï¼‰
        candidates = [
            f"lib/{import_str}",
            f"lib/{import_str}.dart"
        ]
        
        for candidate in candidates:
            if candidate in self.all_files:
                return candidate
        
        return None
    
    def mark_used_files(self):
        """æ ‡è®°è¢«ä½¿ç”¨çš„æ–‡ä»¶"""
        print("ğŸ¯ æ ‡è®°ä½¿ç”¨çš„æ–‡ä»¶...")
        
        # 1. æ ‡è®°å…¥å£æ–‡ä»¶
        entry_count = 0
        for entry in self.entry_files:
            if entry in self.all_files:
                self.used_files.add(entry)
                entry_count += 1
        print(f"   å…¥å£æ–‡ä»¶: {entry_count}ä¸ª")
        
        # 2. æ ‡è®°é‡è¦æ–‡ä»¶
        important_count = 0
        for file_path in self.all_files:
            if self.file_info[file_path]['is_important']:
                self.used_files.add(file_path)
                important_count += 1
        print(f"   é‡è¦æ–‡ä»¶: {important_count}ä¸ª")
        
        # 3. é€’å½’æ ‡è®°ç›´æ¥å’Œé—´æ¥ä¾èµ–
        changed = True
        iteration = 0
        
        while changed and iteration < 50:
            changed = False
            iteration += 1
            old_count = len(self.used_files)
            
            for used_file in list(self.used_files):
                # æ ‡è®°å¯¼å…¥çš„æ–‡ä»¶
                for imported in self.imports.get(used_file, set()):
                    if imported not in self.used_files:
                        self.used_files.add(imported)
                        changed = True
                
                # æ ‡è®°å¯¼å‡ºçš„æ–‡ä»¶
                for exported in self.exports.get(used_file, set()):
                    if exported not in self.used_files:
                        self.used_files.add(exported)
                        changed = True
            
            new_count = len(self.used_files)
            if new_count > old_count:
                print(f"     ç¬¬{iteration}è½®: +{new_count - old_count}ä¸ª")
        
        lib_used = len([f for f in self.used_files if f.startswith('lib/')])
        print(f"   æœ€ç»ˆæ ‡è®°: {lib_used}ä¸ªlibæ–‡ä»¶")
    
    def deep_validate_unused(self, unused_files: List[str]) -> Dict:
        """æ·±åº¦éªŒè¯æœªä½¿ç”¨æ–‡ä»¶"""
        print(f"ğŸ”¬ æ·±åº¦éªŒè¯ {len(unused_files)} ä¸ªæœªä½¿ç”¨æ–‡ä»¶...")
        
        validation = {
            'total': len(unused_files),
            'confirmed_unused': 0,
            'likely_used': 0,
            'likely_used_files': []
        }
        
        for file_path in unused_files:
            is_likely_used = False
            reasons = []
            
            # æ£€æŸ¥æ˜¯å¦è¢«å­—ç¬¦ä¸²å¼•ç”¨ï¼ˆåŠ¨æ€å¯¼å…¥ï¼‰
            file_name = Path(file_path).stem
            base_name = file_name.lower()
            
            for check_file in self.all_files:
                if check_file == file_path:
                    continue
                
                try:
                    with open(self.file_info[check_file]['path_obj'], 'r', encoding='utf-8') as f:
                        content = f.read().lower()
                    
                    # æ£€æŸ¥å¤šç§å¯èƒ½çš„å¼•ç”¨æ–¹å¼
                    if (base_name in content or 
                        file_path.lower() in content or
                        f"'{file_path}'" in content.lower() or
                        f'"{file_path}"' in content.lower()):
                        is_likely_used = True
                        reasons.append(f"è¢«{check_file}å¼•ç”¨")
                        break
                        
                except:
                    continue
            
            # æ£€æŸ¥æ–‡ä»¶åæ¨¡å¼ï¼ˆå¯èƒ½è¢«åŠ¨æ€å¼•ç”¨ï¼‰
            if self.file_info[file_path]['is_dynamic']:
                is_likely_used = True
                reasons.append("å¯èƒ½è¢«åŠ¨æ€å¼•ç”¨")
            
            if is_likely_used:
                validation['likely_used'] += 1
                validation['likely_used_files'].append({
                    'file': file_path,
                    'reasons': reasons
                })
            else:
                validation['confirmed_unused'] += 1
        
        return validation
    
    def classify_and_validate(self) -> Dict:
        """åˆ†ç±»å¹¶éªŒè¯æœªä½¿ç”¨æ–‡ä»¶"""
        print("ğŸ“Š åˆ†ç±»å’ŒéªŒè¯æœªä½¿ç”¨æ–‡ä»¶...")
        
        categories = {
            'empty_files': [],
            'safe_delete': [],
            'needs_review': [],
            'likely_false_positive': []
        }
        
        lib_unused = [f for f in self.all_files if f.startswith('lib/') and f not in self.used_files]
        
        # æ·±åº¦éªŒè¯
        validation = self.deep_validate_unused(lib_unused)
        
        for file_path in lib_unused:
            info = self.file_info[file_path]
            
            file_data = {
                'path': file_path,
                'size_kb': info['size'] / 1024,
                'size_bytes': info['size']
            }
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å¯èƒ½ä½¿ç”¨åˆ—è¡¨ä¸­
            is_likely_used = any(item['file'] == file_path for item in validation['likely_used_files'])
            
            if is_likely_used:
                categories['likely_false_positive'].append(file_data)
            elif info['is_empty']:
                categories['empty_files'].append(file_data)
            elif info['size'] < 1000:
                categories['safe_delete'].append(file_data)
            else:
                categories['needs_review'].append(file_data)
        
        return categories, validation
    
    def generate_final_report(self) -> str:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        categories, validation = self.classify_and_validate()
        
        # ç»Ÿè®¡
        total_lib = len([f for f in self.all_files if f.startswith('lib/')])
        total_unused = sum(len(cat) for cat in categories.values())
        total_used = total_lib - total_unused
        
        # è®¡ç®—å®é™…æœªä½¿ç”¨ï¼ˆæ’é™¤è¯¯æŠ¥ï¼‰
        actual_unused = total_unused - len(categories['likely_false_positive'])
        
        lines = []
        lines.append("=" * 80)
        lines.append("ğŸ“Š æœ€ç»ˆé«˜ç²¾åº¦æœªä½¿ç”¨æ–‡ä»¶åˆ†ææŠ¥å‘Š")
        lines.append("=" * 80)
        lines.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        lines.append("ğŸ“ˆ ç²¾ç¡®ç»Ÿè®¡:")
        lines.append(f"   libæ–‡ä»¶æ€»æ•°: {total_lib}")
        lines.append(f"   å·²ä½¿ç”¨æ–‡ä»¶: {total_used} ({total_used/total_lib*100:.1f}%)")
        lines.append(f"   æŠ¥å‘Šæœªä½¿ç”¨: {total_unused} ({total_unused/total_lib*100:.1f}%)")
        lines.append(f"   å¯èƒ½è¯¯æŠ¥: {len(categories['likely_false_positive'])}")
        lines.append(f"   å®é™…æœªä½¿ç”¨: {actual_unused} ({actual_unused/total_lib*100:.1f}%)")
        lines.append("")
        
        # éªŒè¯ç»“æœ
        if validation['total'] > 0:
            accuracy = validation['confirmed_unused'] / validation['total'] * 100
            lines.append("ğŸ”¬ æ·±åº¦éªŒè¯ç»“æœ:")
            lines.append(f"   æ€»éªŒè¯æ–‡ä»¶: {validation['total']}")
            lines.append(f"   ç¡®è®¤æœªä½¿ç”¨: {validation['confirmed_unused']}")
            lines.append(f"   å¯èƒ½ä½¿ç”¨: {validation['likely_used']}")
            lines.append(f"   é¢„ä¼°å‡†ç¡®ç‡: {accuracy:.1f}%")
            lines.append("")
        
        # åˆ†ç±»ç»Ÿè®¡
        lines.append("ğŸ“‚ ç²¾ç¡®åˆ†ç±»:")
        for category, files in categories.items():
            if files:
                total_size = sum(f['size_kb'] for f in files)
                lines.append(f"   {self._get_category_name(category)}: {len(files)}ä¸ª ({total_size:.1f}KB)")
        lines.append("")
        
        # æ“ä½œå»ºè®®
        lines.append("ğŸ¯ ç²¾ç¡®å»ºè®®:")
        if categories['empty_files']:
            lines.append(f"   âœ… å®‰å…¨åˆ é™¤ç©ºæ–‡ä»¶: {len(categories['empty_files'])}ä¸ª")
        if categories['safe_delete']:
            lines.append(f"   âš ï¸  è°¨æ…åˆ é™¤å°æ–‡ä»¶: {len(categories['safe_delete'])}ä¸ª")
        if categories['needs_review']:
            lines.append(f"   ğŸ” äººå·¥å®¡æŸ¥å¤§æ–‡ä»¶: {len(categories['needs_review'])}ä¸ª")
        if categories['likely_false_positive']:
            lines.append(f"   âŒ å¿½ç•¥å¯èƒ½è¯¯æŠ¥: {len(categories['likely_false_positive'])}ä¸ª")
        lines.append("")
        
        # ç©ºæ–‡ä»¶è¯¦æƒ…ï¼ˆå¯ä»¥ç«‹å³åˆ é™¤ï¼‰
        if categories['empty_files']:
            lines.append("ğŸ—‘ï¸  å¯ç«‹å³åˆ é™¤çš„ç©ºæ–‡ä»¶:")
            for file_data in categories['empty_files']:
                lines.append(f"   - {file_data['path']}")
            lines.append("")
        
        return "\n".join(lines)
    
    def _get_category_name(self, category: str) -> str:
        """åˆ†ç±»åç§°"""
        names = {
            'empty_files': 'ç©ºæ–‡ä»¶',
            'safe_delete': 'å®‰å…¨åˆ é™¤',
            'needs_review': 'éœ€è¦å®¡æŸ¥',
            'likely_false_positive': 'å¯èƒ½è¯¯æŠ¥'
        }
        return names.get(category, category)
    
    def run_final_analysis(self):
        """è¿è¡Œæœ€ç»ˆåˆ†æ"""
        print("ğŸš€ å¯åŠ¨æœ€ç»ˆé«˜ç²¾åº¦åˆ†æ")
        print(f"ğŸ“ é¡¹ç›®: {self.project_root}")
        print()
        
        self.scan_files()
        self.analyze_dependencies()
        self.mark_used_files()
        
        report = self.generate_final_report()
        print(report)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.project_root / 'tools' / 'reports' / 'final_precise_analysis.txt'
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“„ æœ€ç»ˆæŠ¥å‘Š: {report_file}")

def main():
    analyzer = FinalPreciseAnalyzer(os.getcwd())
    analyzer.run_final_analysis()

if __name__ == "__main__":
    main() 