#!/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆæœªä½¿ç”¨æ–‡ä»¶åˆ†æå·¥å…·
ä¸»è¦æ”¹è¿›ï¼š
1. æ›´ç²¾ç¡®çš„å¯¼å…¥è·¯å¾„è§£æ
2. ç‰¹æ®Šæ–‡ä»¶è¯†åˆ«ï¼ˆprovidersã€servicesç­‰ï¼‰
3. äº¤å‰éªŒè¯å‡å°‘è¯¯æŠ¥
4. æŒ‰é£é™©ç­‰çº§åˆ†ç±»
"""

import os
import re
import json
from pathlib import Path
from typing import Set, Dict, List, Optional

class ImprovedAnalyzer:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root).resolve()
        self.lib_dir = self.project_root / 'lib'
        
        # æ•°æ®å­˜å‚¨
        self.all_files: Set[str] = set()
        self.import_map: Dict[str, Set[str]] = {}
        self.used_files: Set[str] = set()
        self.file_info: Dict[str, dict] = {}
        
        # å…¥å£æ–‡ä»¶
        self.entry_files = [
            'lib/main.dart',
            'lib/app.dart', 
            'lib/presentation/app.dart',
            'lib/providers.dart',
            'lib/routes/app_routes.dart'
        ]
        
        # ç‰¹æ®Šæ–‡ä»¶æ¨¡å¼ï¼ˆé€šå¸¸è¢«åŠ¨æ€å¼•ç”¨ï¼‰
        self.special_patterns = [
            r'provider.*\.dart$',
            r'service.*\.dart$', 
            r'repository.*\.dart$',
            r'route.*\.dart$',
            r'navigation.*\.dart$',
            r'mixin.*\.dart$',
            r'extension.*\.dart$'
        ]
    
    def scan_files(self):
        """æ‰«ææ‰€æœ‰æœ‰æ•ˆçš„Dartæ–‡ä»¶"""
        print("ğŸ” æ‰«æDartæ–‡ä»¶...")
        
        for dart_file in self.lib_dir.rglob('*.dart'):
            # æ’é™¤ç”Ÿæˆçš„æ–‡ä»¶
            if dart_file.name.endswith('.g.dart') or dart_file.name.endswith('.freezed.dart'):
                continue
                
            rel_path = str(dart_file.relative_to(self.project_root)).replace('\\', '/')
            self.all_files.add(rel_path)
            
            # æ”¶é›†æ–‡ä»¶ä¿¡æ¯
            stat = dart_file.stat()
            self.file_info[rel_path] = {
                'size': stat.st_size,
                'is_empty': stat.st_size < 50,
                'is_special': self._is_special_file(rel_path),
                'path_obj': dart_file
            }
        
        print(f"   å‘ç° {len(self.all_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
    
    def _is_special_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹æ®Šæ–‡ä»¶"""
        file_lower = file_path.lower()
        return any(re.search(pattern, file_lower) for pattern in self.special_patterns)
    
    def analyze_imports(self):
        """åˆ†æå¯¼å…¥å…³ç³»"""
        print("ğŸ“š åˆ†æå¯¼å…¥å…³ç³»...")
        
        for rel_path in self.all_files:
            imports = self._extract_imports(rel_path)
            self.import_map[rel_path] = imports
        
        total_imports = sum(len(imports) for imports in self.import_map.values())
        print(f"   è§£æäº† {total_imports} ä¸ªå¯¼å…¥å…³ç³»")
    
    def _extract_imports(self, rel_path: str) -> Set[str]:
        """æå–æ–‡ä»¶çš„å¯¼å…¥"""
        imports = set()
        file_path = self.file_info[rel_path]['path_obj']
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception:
            return imports
        
        # æ¸…ç†å†…å®¹ï¼Œç§»é™¤æ³¨é‡Š
        content = self._clean_content(content)
        
        # æå–importè¯­å¥
        import_patterns = [
            r"import\s+['\"]([^'\"]+)['\"]",
            r"export\s+['\"]([^'\"]+)['\"]", 
            r"part\s+['\"]([^'\"]+)['\"]"
        ]
        
        for pattern in import_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                resolved = self._resolve_import(match, rel_path)
                if resolved:
                    imports.add(resolved)
        
        return imports
    
    def _clean_content(self, content: str) -> str:
        """æ¸…ç†å†…å®¹ï¼Œç§»é™¤æ³¨é‡Šå’Œå­—ç¬¦ä¸²"""
        lines = []
        for line in content.split('\n'):
            # ç§»é™¤å•è¡Œæ³¨é‡Š
            if '//' in line:
                line = line[:line.find('//')]
            lines.append(line)
        return '\n'.join(lines)
    
    def _resolve_import(self, import_str: str, current_file: str) -> Optional[str]:
        """è§£æå¯¼å…¥è·¯å¾„"""
        # package:demo/ å¯¼å…¥
        if import_str.startswith('package:demo/'):
            target = import_str.replace('package:demo/', 'lib/')
            return target if target in self.all_files else None
        
        # å¿½ç•¥å¤–éƒ¨åŒ…å’Œdart:
        if import_str.startswith('package:') or import_str.startswith('dart:'):
            return None
        
        # ç›¸å¯¹è·¯å¾„å¯¼å…¥
        if import_str.startswith('.'):
            try:
                current_dir = Path(current_file).parent
                target_path = (current_dir / import_str).resolve()
                rel_target = str(target_path.relative_to(self.project_root)).replace('\\', '/')
                return rel_target if rel_target in self.all_files else None
            except:
                return None
        
        # ç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºlibï¼‰
        candidates = [
            f"lib/{import_str}",
            f"lib/{import_str}.dart"
        ]
        
        for candidate in candidates:
            if candidate in self.all_files:
                return candidate
        
        return None
    
    def mark_used_files(self):
        """æ ‡è®°è¢«ä½¿ç”¨çš„æ–‡ä»¶"""
        print("ğŸ¯ æ ‡è®°ä½¿ç”¨çš„æ–‡ä»¶...")
        
        # 1. æ ‡è®°å…¥å£æ–‡ä»¶
        for entry in self.entry_files:
            if entry in self.all_files:
                self.used_files.add(entry)
        
        # 2. æ ‡è®°ç‰¹æ®Šæ–‡ä»¶ï¼ˆprovidersã€servicesç­‰ï¼‰
        for file_path in self.all_files:
            if self.file_info[file_path]['is_special']:
                self.used_files.add(file_path)
        
        # 3. é€’å½’æ ‡è®°è¢«å¯¼å…¥çš„æ–‡ä»¶
        changed = True
        iteration = 0
        
        while changed and iteration < 50:
            changed = False
            iteration += 1
            old_count = len(self.used_files)
            
            for used_file in list(self.used_files):
                for imported in self.import_map.get(used_file, set()):
                    if imported not in self.used_files:
                        self.used_files.add(imported)
                        changed = True
            
            new_count = len(self.used_files)
            if new_count > old_count:
                print(f"     ç¬¬{iteration}è½®: +{new_count - old_count}ä¸ªæ–‡ä»¶")
        
        lib_used = len([f for f in self.used_files if f.startswith('lib/')])
        print(f"   æœ€ç»ˆæ ‡è®° {lib_used} ä¸ªlibæ–‡ä»¶ä¸ºå·²ä½¿ç”¨")
    
    def classify_unused_files(self) -> Dict[str, List[dict]]:
        """åˆ†ç±»æœªä½¿ç”¨çš„æ–‡ä»¶"""
        categories = {
            'empty_files': [],      # ç©ºæ–‡ä»¶
            'safe_delete': [],      # å®‰å…¨åˆ é™¤
            'need_review': [],      # éœ€è¦å®¡æŸ¥
            'special_files': []     # ç‰¹æ®Šæ–‡ä»¶
        }
        
        for file_path in self.all_files:
            if file_path.startswith('lib/') and file_path not in self.used_files:
                info = self.file_info[file_path]
                
                file_data = {
                    'path': file_path,
                    'size_kb': info['size'] / 1024,
                    'size_bytes': info['size']
                }
                
                if info['is_empty']:
                    categories['empty_files'].append(file_data)
                elif info['is_special']:
                    categories['special_files'].append(file_data)
                elif info['size'] < 1000:
                    categories['safe_delete'].append(file_data)
                else:
                    categories['need_review'].append(file_data)
        
        return categories
    
    def cross_validate(self, unused_files: List[str], sample_size: int = 25) -> dict:
        """äº¤å‰éªŒè¯æœªä½¿ç”¨æ–‡ä»¶"""
        print(f"ğŸ”¬ äº¤å‰éªŒè¯{sample_size}ä¸ªæ–‡ä»¶...")
        
        validation = {
            'total_checked': 0,
            'confirmed_unused': 0,
            'false_positives': 0,
            'false_positive_files': []
        }
        
        sample = unused_files[:sample_size]
        
        for file_path in sample:
            validation['total_checked'] += 1
            
            # æœç´¢æ–‡ä»¶å¼•ç”¨
            is_referenced = False
            file_name = Path(file_path).stem
            
            for check_path in self.all_files:
                if check_path == file_path:
                    continue
                
                try:
                    with open(self.file_info[check_path]['path_obj'], 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if (file_path in content or 
                        file_name in content or
                        f"'{file_path}'" in content):
                        is_referenced = True
                        validation['false_positive_files'].append(file_path)
                        break
                        
                except:
                    continue
            
            if is_referenced:
                validation['false_positives'] += 1
            else:
                validation['confirmed_unused'] += 1
        
        return validation
    
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        categories = self.classify_unused_files()
        
        # è·å–æ‰€æœ‰æœªä½¿ç”¨æ–‡ä»¶ç”¨äºéªŒè¯
        all_unused = []
        for cat_files in categories.values():
            all_unused.extend([f['path'] for f in cat_files])
        
        validation = self.cross_validate(all_unused)
        
        # ç»Ÿè®¡
        total_lib = len([f for f in self.all_files if f.startswith('lib/')])
        total_unused = len(all_unused)
        total_used = total_lib - total_unused
        
        # ç”ŸæˆæŠ¥å‘Š
        lines = []
        lines.append("=" * 70)
        lines.append("ğŸ“Š æ”¹è¿›ç‰ˆæœªä½¿ç”¨æ–‡ä»¶åˆ†ææŠ¥å‘Š")
        lines.append("=" * 70)
        lines.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        lines.append("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        lines.append(f"   libæ–‡ä»¶æ€»æ•°: {total_lib}")
        lines.append(f"   å·²ä½¿ç”¨æ–‡ä»¶: {total_used} ({total_used/total_lib*100:.1f}%)")
        lines.append(f"   æœªä½¿ç”¨æ–‡ä»¶: {total_unused} ({total_unused/total_lib*100:.1f}%)")
        lines.append("")
        
        # éªŒè¯ç»“æœ
        if validation['total_checked'] > 0:
            accuracy = validation['confirmed_unused'] / validation['total_checked'] * 100
            lines.append("ğŸ”¬ äº¤å‰éªŒè¯ç»“æœ:")
            lines.append(f"   éªŒè¯æ ·æœ¬: {validation['total_checked']}ä¸ª")
            lines.append(f"   ç¡®è®¤æœªä½¿ç”¨: {validation['confirmed_unused']}ä¸ª")
            lines.append(f"   è¯¯æŠ¥: {validation['false_positives']}ä¸ª")
            lines.append(f"   å‡†ç¡®ç‡ä¼°è®¡: {accuracy:.1f}%")
            lines.append("")
        
        # åˆ†ç±»ç»Ÿè®¡
        lines.append("ğŸ“‚ æ–‡ä»¶åˆ†ç±»:")
        for category, files in categories.items():
            if files:
                total_size = sum(f['size_kb'] for f in files)
                lines.append(f"   {self._category_name(category)}: {len(files)}ä¸ª ({total_size:.1f}KB)")
        lines.append("")
        
        # åˆ é™¤å»ºè®®
        lines.append("ğŸ¯ å»ºè®®æ“ä½œ:")
        if categories['empty_files']:
            lines.append(f"   âœ… ç«‹å³åˆ é™¤ç©ºæ–‡ä»¶: {len(categories['empty_files'])}ä¸ª")
        if categories['safe_delete']:
            lines.append(f"   âš ï¸  è°¨æ…åˆ é™¤å°æ–‡ä»¶: {len(categories['safe_delete'])}ä¸ª")
        if categories['need_review']:
            lines.append(f"   ğŸ” äººå·¥å®¡æŸ¥å¤§æ–‡ä»¶: {len(categories['need_review'])}ä¸ª")
        if categories['special_files']:
            lines.append(f"   âŒ ç‰¹æ®Šæ–‡ä»¶éœ€ç¡®è®¤: {len(categories['special_files'])}ä¸ª")
        lines.append("")
        
        # è¯¦ç»†åˆ—è¡¨ï¼ˆæ˜¾ç¤ºå‰5ä¸ªï¼‰
        for category, files in categories.items():
            if files:
                lines.append(f"ğŸ“‹ {self._category_name(category)} (å‰5ä¸ª):")
                for file_data in files[:5]:
                    lines.append(f"   - {file_data['path']} ({file_data['size_kb']:.1f}KB)")
                if len(files) > 5:
                    lines.append(f"   ... è¿˜æœ‰{len(files)-5}ä¸ª")
                lines.append("")
        
        return "\n".join(lines)
    
    def _category_name(self, category: str) -> str:
        """åˆ†ç±»åç§°ç¿»è¯‘"""
        names = {
            'empty_files': 'ç©ºæ–‡ä»¶',
            'safe_delete': 'å®‰å…¨åˆ é™¤',
            'need_review': 'éœ€è¦å®¡æŸ¥',
            'special_files': 'ç‰¹æ®Šæ–‡ä»¶'
        }
        return names.get(category, category)
    
    def run_analysis(self):
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¯åŠ¨æ”¹è¿›ç‰ˆæœªä½¿ç”¨æ–‡ä»¶åˆ†æ")
        print(f"ğŸ“ é¡¹ç›®: {self.project_root}")
        print()
        
        self.scan_files()
        self.analyze_imports()
        self.mark_used_files()
        
        report = self.generate_report()
        print(report)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.project_root / 'tools' / 'reports' / 'improved_analysis.txt'
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    analyzer = ImprovedAnalyzer(os.getcwd())
    analyzer.run_analysis()

if __name__ == "__main__":
    main() 