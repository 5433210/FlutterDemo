#!/usr/bin/env python3
"""
å¤šè¯­è¨€æ˜ å°„æ–‡ä»¶åº”ç”¨å™¨ - æ”¯æŒå¹²è¿è¡Œæ¨¡å¼
åŸºäºæ˜ å°„æ–‡ä»¶åº”ç”¨ä»£ç æ›¿æ¢å’ŒARBæ›´æ–°
"""

import os
import re
import json
import yaml
import glob
import argparse
from collections import OrderedDict
from datetime import datetime

# é…ç½®å¸¸é‡
CODE_DIR = "lib"
ARB_DIR = "lib/l10n"
ZH_ARB_PATH = os.path.join(ARB_DIR, "app_zh.arb")
EN_ARB_PATH = os.path.join(ARB_DIR, "app_en.arb")

class MultilingualMappingApplier:
    def __init__(self, mapping_file_path, dry_run=False):
        self.mapping_file_path = mapping_file_path        self.dry_run = dry_run
        self.mapping_data = None
        self.zh_arb_data = OrderedDict()
        self.en_arb_data = OrderedDict()
        self.changes_preview = []
        
    def load_mapping_file(self):
        """åŠ è½½æ˜ å°„æ–‡ä»¶"""
        try:
            with open(self.mapping_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # é¢„å¤„ç†å†…å®¹ï¼Œä¿®å¤YAMLè¯­æ³•é—®é¢˜ï¼ˆå¦‚æ¨¡æ¿è¯­æ³• {xxx}ï¼‰
            content = self.preprocess_yaml_content(content)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯OrderedDictæ ¼å¼
            if '!!python/object/apply:collections.OrderedDict' in content:
                # ä½¿ç”¨unsafe_loadå¤„ç†OrderedDictæ ¼å¼
                self.mapping_data = yaml.unsafe_load(content)
                print(f"âœ… æˆåŠŸåŠ è½½æ˜ å°„æ–‡ä»¶ (OrderedDictæ ¼å¼): {self.mapping_file_path}")
            else:
                # æ ‡å‡†YAMLæ ¼å¼
                self.mapping_data = yaml.safe_load(content)
                print(f"âœ… æˆåŠŸåŠ è½½æ˜ å°„æ–‡ä»¶ (æ ‡å‡†YAMLæ ¼å¼): {self.mapping_file_path}")
            
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
            print(f"æ–‡ä»¶è·¯å¾„: {self.mapping_file_path}")
            return False
    
    def preprocess_yaml_content(self, content):
        """é¢„å¤„ç†YAMLå†…å®¹ï¼Œä¿®å¤å¸¸è§çš„è¯­æ³•é—®é¢˜"""
        import re
        
        # æ‰¾åˆ°æ‰€æœ‰åŒ…å« {xxx} çš„è¡Œå¹¶ä¿®å¤
        lines = content.split('\n')
        fixed_lines = []
        fixed_count = 0
        
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦åŒ…å« {xxx} æ¨¡å¼ä¸”ä¸åœ¨å¼•å·å†…
            if re.search(r'\{[^}]+\}', line) and ':' in line:
                # å¦‚æœè¡ŒåŒ…å«å†’å·å’Œå¤§æ‹¬å·ï¼Œç¡®ä¿å€¼éƒ¨åˆ†è¢«æ­£ç¡®å¼•ç”¨
                if ': ' in line:
                    key_part, value_part = line.split(': ', 1)
                    # å¦‚æœå€¼éƒ¨åˆ†åŒ…å« {xxx} ä¸”æ²¡æœ‰è¢«å¼•å·åŒ…å›´ï¼Œæ·»åŠ å¼•å·
                    if re.search(r'\{[^}]+\}', value_part):
                        if not (value_part.startswith('"') and value_part.endswith('"')):
                            if not (value_part.startswith("'") and value_part.endswith("'")):
                                line = f"{key_part}: \"{value_part}\""
                                fixed_count += 1
            
            fixed_lines.append(line)
        
        if fixed_count > 0:
            print(f"ğŸ”§ ä¿®å¤äº† {fixed_count} ä¸ªYAMLè¯­æ³•é—®é¢˜")
        
        return '\n'.join(fixed_lines)
    
    def load_arb_files(self):
        """åŠ è½½ç°æœ‰ARBæ–‡ä»¶"""
        # åŠ è½½ä¸­æ–‡ARB
        if os.path.exists(ZH_ARB_PATH):
            with open(ZH_ARB_PATH, 'r', encoding='utf-8') as f:
                self.zh_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        # åŠ è½½è‹±æ–‡ARB
        if os.path.exists(EN_ARB_PATH):
            with open(EN_ARB_PATH, 'r', encoding='utf-8') as f:
                self.en_arb_data = json.load(f, object_pairs_hook=OrderedDict)
        
        print(f"âœ… å·²åŠ è½½ARBæ–‡ä»¶ - ä¸­æ–‡: {len(self.zh_arb_data)} é”®, è‹±æ–‡: {len(self.en_arb_data)} é”®")
    
    def analyze_mappings(self):
        """åˆ†ææ˜ å°„æ•°æ®ï¼Œç»Ÿè®¡å„ç§æ“ä½œ"""
        stats = {
            'total_items': 0,
            'approved_items': 0,
            'reuse_items': 0,
            'create_items': 0,
            'chinese_items': 0,
            'english_items': 0
        }
        
        # å¤„ç†OrderedDictæ ¼å¼çš„æ•°æ®ç»“æ„
        if isinstance(self.mapping_data, OrderedDict):
            # OrderedDictæ ¼å¼: [(key, value), ...]
            for lang_key, lang_mappings in self.mapping_data.items():
                if isinstance(lang_mappings, OrderedDict):
                    for category_key, category_mappings in lang_mappings.items():
                        if isinstance(category_mappings, OrderedDict):
                            for key, mapping_info in category_mappings.items():
                                self._analyze_single_mapping(mapping_info, stats)
        else:
            # æ ‡å‡†å­—å…¸æ ¼å¼
            for lang_mappings in self.mapping_data.values():
                for category_mappings in lang_mappings.values():
                    for key, mapping_info in category_mappings.items():
                        self._analyze_single_mapping(mapping_info, stats)
        
        return stats
    
    def _analyze_single_mapping(self, mapping_info, stats):
        """åˆ†æå•ä¸ªæ˜ å°„æ¡ç›®"""
        stats['total_items'] += 1
        
        if mapping_info.get('approved', False):
            stats['approved_items'] += 1
        
        if mapping_info.get('action') == 'reuse_existing':
            stats['reuse_items'] += 1
        elif mapping_info.get('action') == 'create_new':
            stats['create_items'] += 1
        
        # é€šè¿‡é”®åæˆ–æ–‡æœ¬å†…å®¹åˆ¤æ–­è¯­è¨€
        if re.search(r'[\u4e00-\u9fff]', mapping_info.get('text_zh', '')):
            stats['chinese_items'] += 1
        else:
            stats['english_items'] += 1
    
    def preview_arb_changes(self):
        """é¢„è§ˆARBæ–‡ä»¶çš„æ›´æ”¹"""
        arb_changes = {'zh': {}, 'en': {}}
        
        # éå†æ‰€æœ‰æ˜ å°„ - æ”¯æŒOrderedDictæ ¼å¼
        def process_mappings(data):
            if isinstance(data, OrderedDict):
                # OrderedDictæ ¼å¼
                for lang_key, lang_mappings in data.items():
                    if isinstance(lang_mappings, OrderedDict):
                        for category_key, category_mappings in lang_mappings.items():
                            if isinstance(category_mappings, OrderedDict):
                                for key, mapping_info in category_mappings.items():
                                    if mapping_info.get('approved', False) and mapping_info.get('action') == 'create_new':
                                        arb_changes['zh'][key] = mapping_info.get('text_zh', '')
                                        arb_changes['en'][key] = mapping_info.get('text_en', '')
            else:
                # æ ‡å‡†å­—å…¸æ ¼å¼
                for lang_mappings in data.values():
                    for category_mappings in lang_mappings.values():
                        for key, mapping_info in category_mappings.items():
                            if mapping_info.get('approved', False) and mapping_info.get('action') == 'create_new':
                                arb_changes['zh'][key] = mapping_info.get('text_zh', '')
                                arb_changes['en'][key] = mapping_info.get('text_en', '')
        
        process_mappings(self.mapping_data)
        return arb_changes
    
    def preview_code_changes(self):
        """é¢„è§ˆä»£ç æ–‡ä»¶çš„æ›´æ”¹"""
        code_changes = []
        
        def process_mappings(data):
            if isinstance(data, OrderedDict):
                # OrderedDictæ ¼å¼
                for lang_key, lang_mappings in data.items():
                    if isinstance(lang_mappings, OrderedDict):
                        for category_key, category_mappings in lang_mappings.items():
                            if isinstance(category_mappings, OrderedDict):
                                for key, mapping_info in category_mappings.items():
                                    if mapping_info.get('approved', False):
                                        self._add_code_change(key, mapping_info, code_changes)
            else:
                # æ ‡å‡†å­—å…¸æ ¼å¼
                for lang_mappings in data.values():
                    for category_mappings in lang_mappings.values():
                        for key, mapping_info in category_mappings.items():
                            if mapping_info.get('approved', False):
                                self._add_code_change(key, mapping_info, code_changes)
        
        process_mappings(self.mapping_data)
        return code_changes
    
    def _add_code_change(self, key, mapping_info, code_changes):
        """æ·»åŠ å•ä¸ªä»£ç æ›´æ”¹åˆ°åˆ—è¡¨"""
        file_path = mapping_info.get('file', '')
        line_num = mapping_info.get('line', 0)
        original_text = mapping_info.get('text_zh', '') or mapping_info.get('text_en', '')
        
        # ç”Ÿæˆæ›¿æ¢æ–‡æœ¬
        replacement = f"S.of(context).{key}"
        
        code_changes.append({
            'file': os.path.join(CODE_DIR, file_path),
            'line': line_num,
            'original': original_text,
            'replacement': replacement,
            'key': key
        })
    
    def run_preview(self):
        """è¿è¡Œé¢„è§ˆæ¨¡å¼"""
        print("ğŸ” === æ˜ å°„æ–‡ä»¶åº”ç”¨é¢„è§ˆ ===")
        
        if not self.load_mapping_file():
            return False
        
        self.load_arb_files()
        
        # åˆ†æç»Ÿè®¡
        stats = self.analyze_mappings()
        print(f"\nğŸ“Š === æ˜ å°„ç»Ÿè®¡ ===")
        print(f"æ€»æ¡ç›®æ•°: {stats['total_items']}")
        print(f"å·²å®¡æ ¸æ¡ç›®: {stats['approved_items']}")
        print(f"å¤ç”¨æ¡ç›®: {stats['reuse_items']}")
        print(f"æ–°å»ºæ¡ç›®: {stats['create_items']}")
        print(f"ä¸­æ–‡æ¡ç›®: {stats['chinese_items']}")
        print(f"è‹±æ–‡æ¡ç›®: {stats['english_items']}")
        
        if stats['approved_items'] == 0:
            print("\nâš ï¸  æ²¡æœ‰å·²å®¡æ ¸çš„æ¡ç›®ï¼Œè¯·å…ˆå®¡æ ¸æ˜ å°„æ–‡ä»¶ä¸­çš„æ¡ç›®ï¼ˆè®¾ç½® approved: trueï¼‰")
            return False
        
        # é¢„è§ˆARBæ›´æ”¹
        arb_changes = self.preview_arb_changes()
        print(f"\nğŸ“ === ARBæ–‡ä»¶æ›´æ”¹é¢„è§ˆ ===")
        print(f"å°†æ·»åŠ  {len(arb_changes['zh'])} ä¸ªæ–°é”®åˆ°ARBæ–‡ä»¶:")
        
        for key in list(arb_changes['zh'].keys())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  {key}:")
            print(f"    zh: {arb_changes['zh'][key]}")
            print(f"    en: {arb_changes['en'][key]}")
        
        if len(arb_changes['zh']) > 5:
            print(f"  ... è¿˜æœ‰ {len(arb_changes['zh']) - 5} ä¸ªé”®")
        
        # é¢„è§ˆä»£ç æ›´æ”¹
        code_changes = self.preview_code_changes()
        print(f"\nğŸ”§ === ä»£ç æ›´æ”¹é¢„è§ˆ ===")
        print(f"å°†æ›´æ”¹ {len(code_changes)} å¤„ä»£ç :")
        
        for change in code_changes[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  æ–‡ä»¶: {change['file']}")
            print(f"  è¡Œå·: {change['line']}")
            print(f"  åŸæ–‡: \"{change['original']}\"")
            print(f"  æ›¿æ¢: {change['replacement']}")
            print()
        
        if len(code_changes) > 5:
            print(f"  ... è¿˜æœ‰ {len(code_changes) - 5} å¤„æ›´æ”¹")
        
        return True
    
    def apply_changes(self):
        """å®é™…åº”ç”¨æ›´æ”¹"""
        print("âš¡ === å¼€å§‹åº”ç”¨æ›´æ”¹ ===")
        
        if not self.load_mapping_file():
            return False
        
        self.load_arb_files()
        
        # åˆ›å»ºå¤‡ä»½
        backup_dir = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(backup_dir, exist_ok=True)
        
        # å¤‡ä»½ARBæ–‡ä»¶
        if os.path.exists(ZH_ARB_PATH):
            import shutil
            shutil.copy2(ZH_ARB_PATH, os.path.join(backup_dir, "app_zh.arb"))
        if os.path.exists(EN_ARB_PATH):
            import shutil
            shutil.copy2(EN_ARB_PATH, os.path.join(backup_dir, "app_en.arb"))
        
        print(f"âœ… åˆ›å»ºå¤‡ä»½: {backup_dir}")
        
        # åº”ç”¨ARBæ›´æ”¹
        arb_changes = self.preview_arb_changes()
        self.zh_arb_data.update(arb_changes['zh'])
        self.en_arb_data.update(arb_changes['en'])
        
        # ä¿å­˜ARBæ–‡ä»¶
        with open(ZH_ARB_PATH, 'w', encoding='utf-8') as f:
            json.dump(self.zh_arb_data, f, ensure_ascii=False, indent=2)
        
        with open(EN_ARB_PATH, 'w', encoding='utf-8') as f:
            json.dump(self.en_arb_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ›´æ–°ARBæ–‡ä»¶: æ·»åŠ äº† {len(arb_changes['zh'])} ä¸ªé”®")
        
        # åº”ç”¨ä»£ç æ›´æ”¹
        code_changes = self.preview_code_changes()
        replaced_count = 0
        
        for change in code_changes:
            if self.replace_in_file(change):
                replaced_count += 1
        
        print(f"âœ… æ›´æ–°ä»£ç æ–‡ä»¶: æ›¿æ¢äº† {replaced_count}/{len(code_changes)} å¤„")
        
        return True
    
    def replace_in_file(self, change):
        """åœ¨æ–‡ä»¶ä¸­æ‰§è¡Œæ›¿æ¢"""
        try:
            if not os.path.exists(change['file']):
                return False
            
            with open(change['file'], 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ„å»ºæœç´¢æ¨¡å¼
            original_text = change['original']
            escaped_text = re.escape(original_text)
            
            # æ›¿æ¢æ¨¡å¼ï¼šå¯»æ‰¾å¼•å·ä¸­çš„æ–‡æœ¬
            pattern = rf'([\'"]){escaped_text}\1'
            replacement = f'S.of(context).{change["key"]}'
            
            new_content = re.sub(pattern, replacement, content)
            
            if new_content != content:
                with open(change['file'], 'w', encoding='utf-8') as f:
                    f.write(new_content)
                return True
            
            return False
        except Exception as e:
            print(f"æ›¿æ¢å¤±è´¥ {change['file']}: {e}")
            return False

def find_latest_mapping_file():
    """æŸ¥æ‰¾æœ€æ–°çš„æ˜ å°„æ–‡ä»¶"""
    pattern = "multilingual_hardcoded_report/multilingual_mapping_*.yaml"
    files = glob.glob(pattern)
    if files:
        return max(files, key=os.path.getmtime)
    return None

def main():
    parser = argparse.ArgumentParser(description='å¤šè¯­è¨€æ˜ å°„æ–‡ä»¶åº”ç”¨å™¨')
    parser.add_argument('--input', '-i', help='æ˜ å°„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dry-run', '-d', action='store_true', help='å¹²è¿è¡Œæ¨¡å¼ï¼Œåªé¢„è§ˆæ›´æ”¹')
    parser.add_argument('--auto-latest', '-a', action='store_true', help='è‡ªåŠ¨ä½¿ç”¨æœ€æ–°æ˜ å°„æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ˜ å°„æ–‡ä»¶è·¯å¾„
    mapping_file = args.input
    if args.auto_latest or not mapping_file:
        latest_file = find_latest_mapping_file()
        if latest_file:
            mapping_file = latest_file
            print(f"ä½¿ç”¨æœ€æ–°æ˜ å°„æ–‡ä»¶: {mapping_file}")
        elif not mapping_file:
            print("âŒ æœªæ‰¾åˆ°æ˜ å°„æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --input æŒ‡å®šæ–‡ä»¶è·¯å¾„")
            return
    
    if not os.path.exists(mapping_file):
        print(f"âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
        return
    
    # åˆ›å»ºåº”ç”¨å™¨
    applier = MultilingualMappingApplier(mapping_file, dry_run=args.dry_run)
    
    if args.dry_run:
        # é¢„è§ˆæ¨¡å¼
        success = applier.run_preview()
        if success:
            print("\nâœ… é¢„è§ˆå®Œæˆï¼å¦‚æœç¡®è®¤æ— è¯¯ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°æ­£å¼åº”ç”¨æ›´æ”¹ã€‚")
    else:
        # å®é™…åº”ç”¨
        print("âš ï¸  å³å°†åº”ç”¨æ›´æ”¹ï¼Œè¿™å°†ä¿®æ”¹ä»£ç æ–‡ä»¶å’ŒARBæ–‡ä»¶ã€‚")
        confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): ")
        if confirm.lower() == 'y':
            applier.apply_changes()
            print("\nğŸ‰ åº”ç”¨å®Œæˆï¼")
        else:
            print("å·²å–æ¶ˆæ“ä½œã€‚")

if __name__ == "__main__":
    main()
