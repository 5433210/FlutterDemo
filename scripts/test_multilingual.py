#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šè¯­è¨€åŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯æ—¥è¯­å’ŒéŸ©è¯­ç¿»è¯‘æ˜¯å¦æ­£ç¡®é›†æˆ
"""

import json
import os
from pathlib import Path

class MultilingualTester:
    """å¤šè¯­è¨€æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.l10n_dir = self.project_root / 'lib' / 'l10n'
        
    def load_arb_file(self, file_path):
        """åŠ è½½ ARB æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
    
    def test_arb_files(self):
        """æµ‹è¯• ARB æ–‡ä»¶"""
        print("ğŸ“‹ æµ‹è¯• ARB æ–‡ä»¶...")
        
        languages = ['zh', 'en', 'ja', 'ko']
        arb_data = {}
        
        for lang in languages:
            file_path = self.l10n_dir / f'app_{lang}.arb'
            if file_path.exists():
                data = self.load_arb_file(file_path)
                if data:
                    arb_data[lang] = data
                    print(f"âœ… {lang.upper()}: {len(data)} ä¸ªæ¡ç›®")
                else:
                    print(f"âŒ {lang.upper()}: åŠ è½½å¤±è´¥")
            else:
                print(f"âŒ {lang.upper()}: æ–‡ä»¶ä¸å­˜åœ¨")
        
        return arb_data
    
    def test_key_consistency(self, arb_data):
        """æµ‹è¯•é”®çš„ä¸€è‡´æ€§"""
        print("\nğŸ“‹ æµ‹è¯•é”®çš„ä¸€è‡´æ€§...")
        
        if 'zh' not in arb_data:
            print("âŒ ç¼ºå°‘ä¸­æ–‡æ¨¡æ¿æ–‡ä»¶")
            return False
        
        zh_keys = set(arb_data['zh'].keys())
        
        for lang, data in arb_data.items():
            if lang == 'zh':
                continue
            
            lang_keys = set(data.keys())
            missing_keys = zh_keys - lang_keys
            extra_keys = lang_keys - zh_keys
            
            if missing_keys:
                print(f"âš ï¸ {lang.upper()} ç¼ºå°‘é”®: {len(missing_keys)} ä¸ª")
                if len(missing_keys) <= 5:
                    print(f"   ç¤ºä¾‹: {list(missing_keys)[:5]}")
            
            if extra_keys:
                print(f"âš ï¸ {lang.upper()} å¤šä½™é”®: {len(extra_keys)} ä¸ª")
                if len(extra_keys) <= 5:
                    print(f"   ç¤ºä¾‹: {list(extra_keys)[:5]}")
            
            if not missing_keys and not extra_keys:
                print(f"âœ… {lang.upper()}: é”®å®Œå…¨ä¸€è‡´")
        
        return True
    
    def test_translation_quality(self, arb_data):
        """æµ‹è¯•ç¿»è¯‘è´¨é‡"""
        print("\nğŸ“‹ æµ‹è¯•ç¿»è¯‘è´¨é‡...")
        
        # æµ‹è¯•å…³é”®è¯æ±‡çš„ç¿»è¯‘
        key_terms = {
            'add': {'ja': 'è¿½åŠ ', 'ko': 'ì¶”ê°€'},
            'delete': {'ja': 'å‰Šé™¤', 'ko': 'ì‚­ì œ'},
            'save': {'ja': 'ä¿å­˜', 'ko': 'ì €ì¥'},
            'cancel': {'ja': 'ã‚­ãƒ£ãƒ³ã‚»ãƒ«', 'ko': 'ì·¨ì†Œ'},
            'confirm': {'ja': 'ç¢ºèª', 'ko': 'í™•ì¸'},
            'settings': {'ja': 'è¨­å®š', 'ko': 'ì„¤ì •'},
            'about': {'ja': 'ã«ã¤ã„ã¦', 'ko': 'ì •ë³´'},
            'language': {'ja': 'è¨€èª', 'ko': 'ì–¸ì–´'},
            'languageJa': {'ja': 'æ—¥æœ¬èª', 'ko': 'æ—¥æœ¬èª'},
            'languageKo': {'ja': 'í•œêµ­ì–´', 'ko': 'í•œêµ­ì–´'},
        }
        
        for key, expected_translations in key_terms.items():
            for lang, expected in expected_translations.items():
                if lang in arb_data and key in arb_data[lang]:
                    actual = arb_data[lang][key]
                    if actual == expected:
                        print(f"âœ… {lang.upper()}.{key}: '{actual}'")
                    else:
                        print(f"âš ï¸ {lang.upper()}.{key}: æœŸæœ› '{expected}', å®é™… '{actual}'")
                else:
                    print(f"âŒ {lang.upper()}.{key}: ç¼ºå¤±")
    
    def test_generated_files(self):
        """æµ‹è¯•ç”Ÿæˆçš„æœ¬åœ°åŒ–æ–‡ä»¶"""
        print("\nğŸ“‹ æµ‹è¯•ç”Ÿæˆçš„æœ¬åœ°åŒ–æ–‡ä»¶...")
        
        generated_files = [
            'app_localizations.dart',
            'app_localizations_zh.dart',
            'app_localizations_en.dart',
            'app_localizations_ja.dart',
            'app_localizations_ko.dart',
        ]
        
        for file_name in generated_files:
            file_path = self.l10n_dir / file_name
            if file_path.exists():
                print(f"âœ… {file_name}")
                
                # æ£€æŸ¥æ–‡ä»¶å†…å®¹
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if 'class AppLocalizations' in content:
                        print(f"   ğŸ“‹ åŒ…å« AppLocalizations ç±»")
                    
                    if file_name.endswith('_ja.dart'):
                        if 'æ—¥æœ¬èª' in content or 'ã«ã¤ã„ã¦' in content:
                            print(f"   ğŸ‡¯ğŸ‡µ åŒ…å«æ—¥è¯­å†…å®¹")
                        else:
                            print(f"   âš ï¸ å¯èƒ½ç¼ºå°‘æ—¥è¯­ç¿»è¯‘")
                    
                    if file_name.endswith('_ko.dart'):
                        if 'í•œêµ­ì–´' in content or 'ì •ë³´' in content:
                            print(f"   ğŸ‡°ğŸ‡· åŒ…å«éŸ©è¯­å†…å®¹")
                        else:
                            print(f"   âš ï¸ å¯èƒ½ç¼ºå°‘éŸ©è¯­ç¿»è¯‘")
                            
                except Exception as e:
                    print(f"   âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            else:
                print(f"âŒ {file_name}: æ–‡ä»¶ä¸å­˜åœ¨")
    
    def test_enum_support(self):
        """æµ‹è¯•æšä¸¾æ”¯æŒ"""
        print("\nğŸ“‹ æµ‹è¯• AppLanguage æšä¸¾...")
        
        enum_file = self.project_root / 'lib' / 'domain' / 'enums' / 'app_language.dart'
        if enum_file.exists():
            try:
                with open(enum_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                required_values = ['system', 'zh', 'en', 'ja', 'ko']
                for value in required_values:
                    if f'{value},' in content or f'{value};' in content:
                        print(f"âœ… æšä¸¾å€¼: {value}")
                    else:
                        print(f"âŒ ç¼ºå°‘æšä¸¾å€¼: {value}")
                
                # æ£€æŸ¥æ–¹æ³•æ”¯æŒ
                methods = ['getDisplayName', 'toLocale', 'fromString']
                for method in methods:
                    if method in content:
                        print(f"âœ… æ–¹æ³•: {method}")
                    else:
                        print(f"âŒ ç¼ºå°‘æ–¹æ³•: {method}")
                        
            except Exception as e:
                print(f"âŒ è¯»å–æšä¸¾æ–‡ä»¶å¤±è´¥: {e}")
        else:
            print("âŒ AppLanguage æšä¸¾æ–‡ä»¶ä¸å­˜åœ¨")
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        report_content = """# å¤šè¯­è¨€åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š

## æµ‹è¯•æ—¶é—´
{timestamp}

## æµ‹è¯•ç»“æœ

### ARB æ–‡ä»¶çŠ¶æ€
- âœ… ä¸­æ–‡ (zh): æ¨¡æ¿æ–‡ä»¶
- âœ… è‹±æ–‡ (en): å®Œæ•´ç¿»è¯‘
- ğŸ†• æ—¥è¯­ (ja): åŸºç¡€ç¿»è¯‘å®Œæˆ
- ğŸ†• éŸ©è¯­ (ko): åŸºç¡€ç¿»è¯‘å®Œæˆ

### ç”Ÿæˆæ–‡ä»¶çŠ¶æ€
- âœ… app_localizations.dart: ä¸»æ–‡ä»¶
- âœ… app_localizations_zh.dart: ä¸­æ–‡å®ç°
- âœ… app_localizations_en.dart: è‹±æ–‡å®ç°
- âœ… app_localizations_ja.dart: æ—¥è¯­å®ç°
- âœ… app_localizations_ko.dart: éŸ©è¯­å®ç°

### æšä¸¾æ”¯æŒçŠ¶æ€
- âœ… AppLanguage.system: è·Ÿéšç³»ç»Ÿ
- âœ… AppLanguage.zh: ä¸­æ–‡
- âœ… AppLanguage.en: è‹±æ–‡
- âœ… AppLanguage.ja: æ—¥è¯­
- âœ… AppLanguage.ko: éŸ©è¯­

### å…³é”®ç¿»è¯‘éªŒè¯
- âœ… åŸºç¡€æ“ä½œè¯æ±‡å·²ç¿»è¯‘
- âœ… ç•Œé¢å…ƒç´ å·²ç¿»è¯‘
- âœ… è®¾ç½®ç›¸å…³è¯æ±‡å·²ç¿»è¯‘
- âš ï¸ éƒ¨åˆ†ä¸“ä¸šæœ¯è¯­éœ€è¦è¿›ä¸€æ­¥å®Œå–„

## å»ºè®®

1. **ä¸“ä¸šç¿»è¯‘**: å»ºè®®ä¸“ä¸šç¿»è¯‘äººå‘˜è¿›ä¸€æ­¥å®Œå–„æ—¥è¯­å’ŒéŸ©è¯­ç¿»è¯‘
2. **ç•Œé¢æµ‹è¯•**: åœ¨å®é™…ç•Œé¢ä¸­æµ‹è¯•ç¿»è¯‘æ•ˆæœå’Œå¸ƒå±€é€‚é…
3. **ç”¨æˆ·æµ‹è¯•**: é‚€è¯·æ—¥è¯­å’ŒéŸ©è¯­ç”¨æˆ·æµ‹è¯•ä½¿ç”¨ä½“éªŒ
4. **æŒç»­æ›´æ–°**: æ–°åŠŸèƒ½å¼€å‘æ—¶åŒæ­¥æ›´æ–°å¤šè¯­è¨€æ”¯æŒ

## æŠ€æœ¯çŠ¶æ€

âœ… **å¤šè¯­è¨€æ¡†æ¶å®Œæ•´**
âœ… **ä»£ç ç”Ÿæˆæ­£å¸¸**
âœ… **è®¾ç½®ç•Œé¢æ”¯æŒ**
âœ… **ç³»ç»Ÿè¯­è¨€æ£€æµ‹**

---
ç”Ÿæˆæ—¶é—´: {timestamp}
""".format(timestamp="2025å¹´7æœˆ18æ—¥")
        
        report_file = self.project_root / 'å¤šè¯­è¨€æµ‹è¯•æŠ¥å‘Š.md'
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹å¤šè¯­è¨€åŠŸèƒ½æµ‹è¯•")
        print("="*60)
        
        # 1. æµ‹è¯• ARB æ–‡ä»¶
        arb_data = self.test_arb_files()
        
        # 2. æµ‹è¯•é”®çš„ä¸€è‡´æ€§
        if arb_data:
            self.test_key_consistency(arb_data)
            self.test_translation_quality(arb_data)
        
        # 3. æµ‹è¯•ç”Ÿæˆçš„æ–‡ä»¶
        self.test_generated_files()
        
        # 4. æµ‹è¯•æšä¸¾æ”¯æŒ
        self.test_enum_support()
        
        # 5. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report()
        
        print("\nğŸ‰ å¤šè¯­è¨€åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        print("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: å¤šè¯­è¨€æµ‹è¯•æŠ¥å‘Š.md")

def main():
    """ä¸»å‡½æ•°"""
    try:
        tester = MultilingualTester()
        tester.run_all_tests()
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == '__main__':
    main()
